{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The unreasonable effectiveness of Character-level Language Models\n",
    "## (and why RNNs are still cool)\n",
    "\n",
    "### [Yoav Goldberg](http://www.cs.biu.ac.il/~yogo)\n",
    "\n",
    "RNNs, LSTMs and Deep Learning are all the rage, and a recent [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy is doing a great job explaining what these models are and how to train them.\n",
    "It also provides some very impressive results of what they are capable of.  This is a great post, and if you are interested in natural language, machine learning or neural networks you should definitely read it. \n",
    "\n",
    "Go read it now, then come back here. \n",
    "\n",
    "You're back? good. Impressive stuff, huh? How could the network learn to immitate the input like that?\n",
    "Indeed. I was quite impressed as well.\n",
    "\n",
    "However, it feels to me that most readers of the post are impressed by the wrong reasons.\n",
    "This is because they are not familiar with **unsmoothed maximum-liklihood character level language models** and their unreasonable effectiveness at generating rather convincing natural language outputs.\n",
    "\n",
    "In what follows I will briefly describe these character-level maximum-likelihood langauge models, which are much less magical than RNNs and LSTMs, and show that they too can produce a rather convincing Shakespearean prose. I will also show about 30 lines of python code that take care of both training the model and generating the output. Compared to this baseline, the RNNs may seem somehwat less impressive. So why was I impressed? I will explain this too, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Maximum Likelihood Character Level Language Model \n",
    "\n",
    "The name is quite long, but the idea is very simple.  We want a model whose job is to guess the next character based on the previous $n$ letters. For example, having seen `ello`, the next characer is likely to be either a commma or space (if we assume is is the end of the word \"hello\"), or the letter `w` if we believe we are in the middle of the word \"mellow\". Humans are quite good at this, but of course seeing a larger history makes things easier (if we were to see 5 letters instead of 4, the choice between space and `w` would have been much easier).\n",
    "\n",
    "We will call $n$, the number of letters we need to guess based on, the _order_ of the language model.\n",
    "\n",
    "RNNs and LSTMs can potentially learn infinite-order language model (they guess the next character based on a \"state\" which supposedly encode all the previous history). We here will restrict ourselves to a fixed-order language model.\n",
    "\n",
    "So, we are seeing $n$ letters, and need to guess the $n+1$th one. We are also given a large-ish amount of text (say, all of Shakespear works) that we can use. How would we go about solving this task?\n",
    "\n",
    "Mathematically, we would like to learn a function $P(c | h)$. Here, $c$ is a character, $h$ is a $n$-letters history, and $P(c|h)$ stands for how likely is it to see $c$ after we've seen $h$.\n",
    "\n",
    "Perhaps the simplest approach would be to just count and divide (a.k.a **maximum likelihood estimates**). We will count the number of times each letter $c'$ appeared after $h$, and divide by the total numbers of letters appearing after $h$. The **unsmoothed** part means that if we did not see a given letter following $h$, we will just give it a probability of zero.\n",
    "\n",
    "And that's all there is to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code\n",
    "Here is the code for training the model. `fname` is a file to read the characters from. `order` is the history size to consult. Note that we pad the data with leading `~` so that we also learn how to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import *\n",
    "\n",
    "def train_char_lm(fname, order=4):\n",
    "    data = open(fname).read()\n",
    "    lm = defaultdict(Counter)\n",
    "    pad = \"~\" * order\n",
    "    data = pad + data\n",
    "    for i in range(len(data)-order):\n",
    "        history, char = data[i:i+order], data[i+order]\n",
    "        lm[history][char]+=1\n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c,cnt/s) for c,cnt in counter.items()]\n",
    "    outlm = {hist:normalize(chars) for hist, chars in lm.items()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it on Andrej's Shakespears's text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-02 08:57:06--  http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt [following]\n",
      "--2024-10-02 08:57:09--  https://www.cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving www.cs.stanford.edu (www.cs.stanford.edu)... 23.216.154.115, 23.216.154.123\n",
      "Connecting to www.cs.stanford.edu (www.cs.stanford.edu)|23.216.154.115|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2024-10-02 08:57:11 ERROR 404: Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now let's do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 0.06912442396313365),\n",
       " (' ', 0.22119815668202766),\n",
       " (\"'\", 0.018433179723502304),\n",
       " (',', 0.20276497695852536),\n",
       " ('-', 0.059907834101382486),\n",
       " ('.', 0.1336405529953917),\n",
       " ('i', 0.03225806451612903),\n",
       " ('\\n', 0.018433179723502304),\n",
       " (':', 0.018433179723502304),\n",
       " (';', 0.027649769585253458),\n",
       " ('?', 0.03225806451612903),\n",
       " ('s', 0.009216589861751152),\n",
       " ('o', 0.15668202764976957)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['hell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w', 0.3333333333333333),\n",
       " ('i', 0.26666666666666666),\n",
       " (' ', 0.13333333333333333),\n",
       " ('e', 0.13333333333333333),\n",
       " ('s', 0.13333333333333333)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['hirl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 0.09550561797752809),\n",
       " ('f', 0.011235955056179775),\n",
       " ('i', 0.016853932584269662),\n",
       " ('t', 0.05377207062600321),\n",
       " ('u', 0.0016051364365971107),\n",
       " ('S', 0.16292134831460675),\n",
       " ('h', 0.019261637239165328),\n",
       " ('s', 0.03290529695024077),\n",
       " ('R', 0.0008025682182985554),\n",
       " ('b', 0.024879614767255216),\n",
       " ('c', 0.012841091492776886),\n",
       " ('O', 0.018459069020866775),\n",
       " ('w', 0.024077046548956663),\n",
       " ('a', 0.02247191011235955),\n",
       " ('m', 0.02247191011235955),\n",
       " ('n', 0.020064205457463884),\n",
       " ('I', 0.009630818619582664),\n",
       " ('L', 0.10674157303370786),\n",
       " ('M', 0.0593900481540931),\n",
       " ('l', 0.01043338683788122),\n",
       " ('o', 0.030497592295345103),\n",
       " ('H', 0.0040128410914927765),\n",
       " ('d', 0.015248796147672551),\n",
       " ('W', 0.033707865168539325),\n",
       " ('K', 0.008025682182985553),\n",
       " ('q', 0.0016051364365971107),\n",
       " ('G', 0.0898876404494382),\n",
       " ('g', 0.011235955056179775),\n",
       " ('k', 0.0040128410914927765),\n",
       " ('e', 0.0032102728731942215),\n",
       " ('y', 0.002407704654895666),\n",
       " ('r', 0.0072231139646869984),\n",
       " ('p', 0.00882825040128411),\n",
       " ('A', 0.0056179775280898875),\n",
       " ('P', 0.014446227929373997),\n",
       " ('F', 0.012038523274478331),\n",
       " ('v', 0.002407704654895666),\n",
       " ('T', 0.0032102728731942215),\n",
       " ('D', 0.0032102728731942215),\n",
       " ('B', 0.009630818619582664),\n",
       " ('N', 0.0008025682182985554),\n",
       " (\"'\", 0.0008025682182985554),\n",
       " ('E', 0.0016051364365971107)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['rst ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `ello` is followed by either space, punctuation or `w` (or `r`, `u`, `n`), `Firs` is pretty much deterministic, and the word following `ist ` can start with pretty much every letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating from the model\n",
    "Generating is also very simple. To generate a letter, we will take the history, look at the last $order$ characteters, and then sample a random letter based on the corresponding distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def generate_letter(lm, history, order):\n",
    "        history = history[-order:]\n",
    "        dist = lm[history]\n",
    "        x = random()\n",
    "        for c,v in dist:\n",
    "            x = x - v\n",
    "            if x <= 0: return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a passage of $k$ characters, we just seed it with the initial history and run letter generation in a loop, updating the history at each turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm, order, nletters=1000):\n",
    "    history = \"~\" * order\n",
    "    out = []\n",
    "    for i in range(nletters):\n",
    "        c = generate_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        out.append(c)\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Shakespeare from different order models\n",
    "\n",
    "Let's try to generate text based on different language-model orders. Let's start with something silly:\n",
    "\n",
    "### order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First id faing.\n",
      "\n",
      "Knot cius, bad, the? wom me, all worn\n",
      "fale him ster OF Sixterandeakey Loolearrep youd I of aft letiles wil pow sestrep uplen:\n",
      "PAGO:\n",
      "To be crojeshaver'd we froy;\n",
      "Whap a lights?\n",
      "\n",
      "Put ditterve ited ch its ing thal!\n",
      "\n",
      "If exce ablen lion.\n",
      "\n",
      "SHYLO:\n",
      "ACUS:\n",
      "Upostell shour younry e' ank whoss heyet Hery mard clion al force ow me his all your Gall wif mallover hout,\n",
      "A mess ever, nothave hold: facte to\n",
      "to frit, I welf;\n",
      "And theribloveak 'stes anty the you\n",
      "At har weakfuld me.\n",
      "\n",
      "PA:\n",
      "Hast is grand als compar ithair, me shenced athere nin:\n",
      "As mard th City bare's I' the beirebear you se\n",
      "That with both I and but mis in don sommors,\n",
      "Tamed,\n",
      "Ser:\n",
      "Oned wourd, eatted\n",
      "AES:\n",
      "I whords pay le\n",
      "Merome fain-gn, sty\n",
      "We hippre\n",
      "Splay,\n",
      "Thent and abell mere'sto hasty withe noteast I andst, mot ine mang a northy your dook whave,\n",
      "Thaver:\n",
      "If stions! that se useect will ant the the\n",
      "For baccusen a\n",
      "fortur cry for ber?\n",
      "\n",
      "GO:\n",
      "Bet, Ha,\n",
      "Blow utly\n",
      "beake strivers mortuare ithis for le haten tholt is a come fin, my twit noner\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=2)\n",
    "print(generate_text(lm, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so great.. but what if we increase the order to 4?\n",
    "\n",
    "### order 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First the storal, in her mindly most his o' mistress well well cale legs wither nature, if you of and thouse.\n",
      "\n",
      "HERMIA:\n",
      "\n",
      "NORTHUMBERLANDO:\n",
      "Pray you get the madam?\n",
      "\n",
      "MARIA:\n",
      "O villant our arms.\n",
      "\n",
      "POSTHUMUS LUCIUS:\n",
      "Welcome, how I not give shut on thee betimes yellow'd, my lord, do o'clock, you, marry eye, man's he is, that can love wrong should gored togetherein thy half the did respect they welcome, King will?\n",
      "\n",
      "CELIA:\n",
      "Away cold,\n",
      "You my rederatian a little very:\n",
      "Third Willion! death false-book, be ever for aught for neither his bear an every peace of dried 'Inest let that done,\n",
      "But in where's grace, that I the done,\n",
      "Yet againstinction off and privy cup, and tractised, met time to makest world\n",
      "corn,\n",
      "And whence. First is numberland's\n",
      "body.\n",
      "\n",
      "PANDA:\n",
      "My pray God spur trains?\n",
      "\n",
      "SHALLOW:\n",
      "Plead quoth of God, cloved, stay be had a fail'd by tyranny me, to stance, if it of thou can.\n",
      "\n",
      "MARTIUS ENOBARBUS:\n",
      "Stand's cur!\n",
      "\n",
      "GLOUCESTER:\n",
      "What, and I gallant look upon them down,\n",
      "Provost:\n",
      "'Tis be-legged I in fight chie\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Gently,\n",
      "Then charm me! I seen;\n",
      "Think the give it privately lord!\n",
      "\n",
      "PRINCENTIO:\n",
      "Willing lord? Who shall I lives in\n",
      "such and call'd too get as seven most degrees; which, infinisters of iron, sir; penitor.\n",
      "\n",
      "LEON:\n",
      "Doubt now much\n",
      "first Out\n",
      "up the great news at the\n",
      "soul,\n",
      "The hath man? In vail'd do I love, no more Mistrength all stillion witness worth\n",
      "Repent for malice;\n",
      "Lay heart, dispring; I was younged wit\n",
      "Who thing but I that I say with him i' the\n",
      "greatenerals! Ah, where ye to be god-dew in Frence, and welcome Ottomach or well my utmost in cond Gentlemanded you are say knife?\n",
      "\n",
      "EDGAR:\n",
      "How now with measure, alack Cassion him the pardon my life;\n",
      "I am the King of you till well have here play ther's but me block'd of a dog they can you love Silvia, cally disclose this the was now you chid?\n",
      "\n",
      "HENRY:\n",
      "It is more long.\n",
      "Foreknow his spection\n",
      "I'll honour torn an in his farth a swain\n",
      "To behalf she deservant:\n",
      "Such ribs,\n",
      "And Indied light!\n",
      "\n",
      "LADY MACBETH:\n",
      "The pity is dunghill,\n",
      "For they heavy.\n",
      "\n",
      "CASCA:\n",
      "He s\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already quite reasonable, and reads like English. Just 4 letters history! What if we increase it to 7?\n",
    "\n",
    "### order 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Clown:\n",
      "Look in your with mine eyes\n",
      "Of dropsies, the odds all you not guilty of her, the prince and\n",
      "desire yet she was my friends, mine eye would not cast away to-night?\n",
      "\n",
      "First Senators, &C:\n",
      "Weapons, such a spousal,\n",
      "That sorrows I might, the scabbard. What married and things I won in France: 'tis a lion and hark.\n",
      "Take up the bourn\n",
      "No travel for green,\n",
      "By all you be call'd neat.--Still virginal fellow that I gather\n",
      "The motto, 'In hac spe vivo.'\n",
      "\n",
      "SIMONIDES:\n",
      "Ay, Timon.\n",
      "\n",
      "Messenger:\n",
      "The south-west: while you shalt bleeding little ease.\n",
      "And are contagious break with her mother!\n",
      "I swear the\n",
      "plain him, Dolabella,\n",
      "A novices! To\n",
      "be slow in my reign.\n",
      "\n",
      "KING PHILIP:\n",
      "What dost thou should have a sectary astronomers for my brother!\n",
      "\n",
      "CORNWALL:\n",
      "How now, my liege, that happy! but move a whip\n",
      "To meet his valour, in\n",
      "true wretches to his honourable man in Windsor was but a finger of wet,\n",
      "The rest.\n",
      "And that sound, sound and a bloody wars,\n",
      "And all too cold a night-bird mute,\n",
      "That not ignorance! Please y\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=7)\n",
    "print(generate_text(lm, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=40)\n",
    "print(generate_text(lm, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works pretty well\n",
    "\n",
    "With an order of 4, we already get quite reasonable results. Increasing the order to 7 (~word and a half of history) or 10 (~two short words of history) already gets us quite passable Shakepearan text. I'd say it is on par with the examples in Andrej's post. And how simple and un-mystical the model is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So why am I impressed with the neural networks after all?\n",
    "\n",
    "Generating English a character at a time -- not so impressive in my view. The NN needs to learn the previous $n$ letters, for a rather small $n$, and that's it. \n",
    "\n",
    "However, the code-generation example is very impressive. Why? because of the context awareness. Note that in all of the posted examples, the code is well indented, the braces and brackets are correctly nested, and even the comments start and end correctly. This is not something that can be achieved by simply looking at the previous $n$ letters. \n",
    "\n",
    "If the examples are not cherry-picked, and the output is generally that nice, then the NN did learn something not trivial at all.\n",
    "\n",
    "Just for the fun of it, let's see what our simple language model does with the linux-kernel code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-02 08:57:25--  http://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt [following]\n",
      "--2024-10-02 08:57:27--  https://www.cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt\n",
      "Resolving www.cs.stanford.edu (www.cs.stanford.edu)... 23.216.154.123, 23.216.154.115\n",
      "Connecting to www.cs.stanford.edu (www.cs.stanford.edu)|23.216.154.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2024-10-02 08:57:28 ERROR 404: Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel.h>\n",
      "#include <linux/mount.h>\n",
      "#include <linux/tracehook.h>\n",
      "#include <linux/notifier.h>\n",
      "#include <linux/sched.h>\n",
      "#include <linux/acct.h>\n",
      "#include <linux/keyctl.h>\n",
      "#include <linux/file.h>\n",
      "#include <linux/kallsyms.h>\n",
      "\n",
      "#include <linux/syscalls.h>\n",
      "#include <linux/time.h\n",
      "\t\t */\n",
      "\t\tasm(\"\" : \"+rm\"(nsec));\n",
      "\t\tnsec -= NSEC_PER_SEC / HZ) * j;\n",
      "#elif HZ > USEC_PER_SEC == 1GHz and @from is NSEC_PER_SEC / USER_HZ)) == 0\n",
      "# if HZ < USER_HZ\n",
      "\tx = div_u64_rem() for another threads\");\n",
      "torture_param(int, stat_interval * clock->mult;\n",
      "\ttk->ntp_error <= 0)) {\n",
      "\t\tret = -ENOMEM;\n",
      "\tnext_key = array_map_lookup_elem = htab_map_free(struct audit_parent structure has multiple\n",
      " * time.\n",
      " *\n",
      " * Called when prev != next.\n",
      " */\n",
      "static void torture_must_stop())\n",
      "\t\t\tbreak;\n",
      "\t\tprev_page = head_page->entries[i]);\n",
      "\t}\n",
      "\tbuf += sprintf(buf, sizeof(buffer) - len;\n",
      "\t\t\tgoto out;\n",
      "\n",
      "\t\t\t/*\n",
      "\t\t\t * We are sharing ->siglock held, which matches with the sighand lock held.\n",
      " */\n",
      "\n",
      "/* unrunnable is < 0 */\n",
      "#define KDB_CMD_KGDB) {\n",
      "\t\tif (new_f\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=10)\n",
    "print(generate_text(lm, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/time/tick-broadcast-hrtimer.c\n",
      " * This file emulates a local clock event devices which handle everything in page size chunks ensure\n",
      "\t * the destination addresses\n",
      "\t * through very weird things can happen\n",
      "\t * if the module is unloaded, and then by giving the lock_torture_stats_print();\n",
      "\t\ttorture_shutdown task started\");\n",
      "\tdo {\n",
      "\t\tschedule_timeout_interruptible(1);\n",
      "\t}\n",
      "\tsmp_mb(); /* matches sched_clock_init() */\n",
      "\n",
      "\tif (!sched_clock_irqtime) {\n",
      "\t\tirqtime_account_hi_update(void)\n",
      "{\n",
      "\tktime_t period;\n",
      "\n",
      "\twrite_seqlock(&tsk->vtime_seqlock);\n",
      "}\n",
      "\n",
      "void * __weak arch_kexec_kernel_verify_sig(image, image->kernel_buf_len);\n",
      "\n",
      "\tif (ret < 0)\n",
      "\t\terrors++;\n",
      "\n",
      "\tnum_tests++;\n",
      "\tret = test_kprobe();\n",
      "\tif (ret < 0)\n",
      "\t\tgoto out_balanced;\n",
      "\n",
      "\tif (env->idle != CPU_NOT_IDLE) &&\n",
      "\t    likely(p->policy != SCHED_NORMAL && policy != SCHED_DEADLINE task.\n",
      " *\n",
      " * Only the static values are converted to jiffies when they are still\n",
      "\t * active. Clear the pending bitmasks, but must still be cleared in our caller bc CLONE_THRE\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=15)\n",
    "print(generate_text(lm, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/chip.c\n",
      " *\n",
      " * Copyright 2003-2007 Red Hat Inc., Durham, North Carolina.\n",
      " * Copyright 2005 Hewlett-Packard Development Company, L.P.\n",
      " * Copyright (C) 2004-2006 Tom Rini <trini@kernel.crashing.org>\n",
      " * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.\n",
      " * Copyright (c) 2003 Patrick Mochel\n",
      " * Copyright (c) 2009 Wind River Systems, Inc.  All Rights Reserved.\n",
      " * Written by David Howells (dhowells@redhat.com)\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful,\n",
      " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU General Public License\n",
      " *  along with this program; if not, you can access it online at\n",
      " * http://www.gnu.org/licenses/gpl-2.0.html.\n",
      " *\n",
      " * Copyright (c) 2001   David Howells (dhowells@redhat.com).\n",
      " * - Derived partially from idea by Andrea Arcangeli <andrea@suse.de>\n",
      " * - Derived also from comments by Linus\n",
      " */\n",
      "#include <linux/swap.h>\n",
      "#include <linux/cpu.h>\n",
      "#i\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=20)\n",
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/autoprobe.c\n",
      " *\n",
      " * Copyright (C) IBM Corporation, 2014\n",
      " *\n",
      " * Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>\n",
      " */\n",
      "\n",
      "#include <linux/module.h>\t/* for MODULE_NAME_LEN via KSYM_SYMBOL_LEN */\n",
      "#include <linux/clocksource.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/mm.h>\n",
      "#include <linux/percpu.h>\n",
      "#include <linux/mount.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/kdb.h>\n",
      "#include <linux/module.h>\n",
      "\n",
      "#include <asm/uaccess.h>\n",
      "\n",
      "/*\n",
      " * mutex protecting text section modification (dynamic code patching).\n",
      " * some users need to sleep (allocating memory...) while they hold this lock.\n",
      " *\n",
      " * NOT exported to modules - patching kernel text is a really delicate matter.\n",
      " */\n",
      "DEFINE_MUTEX(trace_types_lock);\n",
      "\n",
      "\treturn ret;\n",
      "}\n",
      "\n",
      "static int update_cpumask(struct cpuset *cs, nodemask_t *new_mems,\n",
      "\t\t     bool cpus_updated, bool mems_updated)\n",
      "{\n",
      "\tbool is_empty;\n",
      "\n",
      "\tspin_lock_irq(&callback_lock);\n",
      "\t\tif (!on_dfl)\n",
      "\t\t\tcpumask_copy(top_cpuset.effective_mems = node_states[N_MEMORY].\n",
      " * Call this routine anyti\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/autoprobe.c\n",
      " *\n",
      " * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar\n",
      " * Copyright(C) 2005-2007, Red Hat, Inc., Ingo Molnar <mingo@redhat.com>\n",
      " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>\n",
      " *  Copyright (C) 2004 Pavel Machek <pavel@ucw.cz>\n",
      " * Copyright (C) 2012 Dario Faggioli <raistlin@linux.it>,\n",
      " *                                       /* 5 bit base 2 exponent, 20 bits mantissa.\n",
      " * The leading bit of the mantissa is not stored, but implied for\n",
      " * non-zero exponents.\n",
      " * Largest encodable value is 50 bits.\n",
      " */\n",
      "\n",
      "#define MANTSIZE2       20                          |\n",
      " *      |                                         ----\\n\");\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int trace_selftest_startup_function_graph(struct tracer *trace, struct trace_array *tr)\n",
      "{\n",
      "\tstart_branch_trace(tr);\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int tk_debug_show_sleep_time, NULL);\n",
      "}\n",
      "\n",
      "static const struct file_operations proc_cgroupstats_operations);\n",
      "\treturn 0;\n",
      "}\n",
      "device_initcall(audit_watch_init);\n",
      "/* Copyright (c) 2011, Google, Inc.\n",
      " *\n",
      " * This software is licensed under the terms of the GNU General Public License\n",
      " * along with this program; if not, you can access it online at\n",
      " * http://www.gnu.org/licenses/>.\n",
      " */\n",
      "\n",
      "#define pr_fmt(fmt)  \"irq: \" fmt\n",
      "\n",
      "#include <linux/ctype.h>\n",
      "#include <linux/kernel.h>\n",
      "#include <linux/export.h>\n",
      "#include <linux/alarmtimer.h>\n",
      "#include <linux/export.h>\n",
      "#include <linux/highmem.h>\n",
      "#include <linux/mutex.h>\n",
      "#include <linux/initrd.h>\n",
      "#include <linux/sched.h>\n",
      "#include <linux/mm.h>\n",
      "#include <linux/irq_work.h>\n",
      "#include <linux/compiler.h>\n",
      "\n",
      "#include \"tick-internal.h\"\n",
      "\n",
      "/* The registered clock event devices */\n",
      "static ssize_t sysfs_unbind_clocksource(struct device *dev, struct device_attribute *attr,\n",
      "\t\t\t\t  const char *buf, size_t nbytes, loff_t off)\n",
      "{\n",
      "\tbool freeze;\n",
      "\n",
      "\tbuf = strstrip(buf);\n",
      "\n",
      "\tif (strcmp(buf, freezer_state_strs(0)) == 0)\n",
      "\t\tfreeze = false;\n",
      "\telse if (strcmp(buf, freezer_state_strs(css_freezer(css)->state));\n",
      "\tseq_putc(m, '\\n');\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static struct task_struct *from, struct task_struct *p;\n",
      "\n",
      "\tif (!futex_cmpxchg_enabled)\n",
      "\t\treturn -ENODEV;\n",
      "\n",
      "\tif (event->group_leader != event) {\n",
      "\t\t\tgroup_sched_out(event, cpuctx, ctx))\n",
      "\t\t\t\tcan_add_hw = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "\n",
      "static void nohz_full_kick_ipi(void *info)\n",
      "{\n",
      "\t__tick_nohz_full_check(void)\n",
      "{\n",
      "\tstruct task_struct *p,\n",
      "\t       struct cpumask *new_mask)\n",
      "{\n",
      "\tstruct rq *rq;\n",
      "\tint weight;\n",
      "\n",
      "\tBUG_ON(!rt_task(p));\n",
      "\n",
      "\treturn p;\n",
      "}\n",
      "\n",
      "/*\n",
      " * See if the non running -deadline tasks on this rq\n",
      " * can be sent to some other CPU where they can preempt\n",
      " * and start executing.\n",
      " */\n",
      "static int rcu_boost(struct rcu_node *rnp)\n",
      "{\n",
      "\tstruct task_struct *p)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\n",
      " again:\n",
      "\traw_spin_lock_irqsave);\n",
      "#endif\n",
      "\n",
      "#ifndef CONFIG_INLINE_READ_LOCK_IRQSAVE\n",
      "unsigned long __lockfunc __raw_##op##_lock_irq(locktype##_t *lock)\t\t\t\\\n",
      "{\t\t\t\t\t\t\t\t\t\\\n",
      "\tfor (;;) {\t\t\t\t\t\t\t\\\n",
      "\t\tpreempt_disable();\n",
      "\tif (waitqueue_active(&area->wq))\n",
      "\t\t\twake_up(&area->wq);\n",
      "\n",
      "\t\ttsk->utask->xol_vaddr;\n",
      "\tif (unlikely(!slot_addr))\n",
      "\t\treturn;\n",
      "\n",
      "\tarea = tsk->mm->uprobes_state.xol_area)\n",
      "\t\tgoto fail;\n",
      "\n",
      "\tif (!area->vaddr) {\n",
      "\t\t/* Try to map as high as possible, this is only a hint. */\n",
      "\t\tarea->vaddr = get_unmapped_area(NULL, TASK_SIZE - PAGE_SIZE,\n",
      "\t\t\t\t\t\tPAGE_SIZE, 0, 0);\n",
      "\t\tif (area->vaddr & ~PAGE_MASK) {\n",
      "\t\t\tret = area->vaddr;\n",
      "\t\t\tgoto fail;\n",
      "\t\t}\n",
      "\t}\n",
      "\tput_online_cpus();\n",
      "\n",
      "\tBLOCKING_INIT_NOTIFIER_HEAD(&pinst->cpumask_change_notifier,\n",
      "\t\t\t\t\t\tnblock);\n",
      "}\n",
      "EXPORT_SYMBOL(_raw_spin_trylock_bh);\n",
      "#endif\n",
      "\n",
      "#ifndef CONFIG_INLINE_WRITE_LOCK\n",
      "void __lockfunc _raw_write_trylock(rwlock_t *lock)\n",
      "{\n",
      "\t__raw_spin_unlock_irq(&pi_state->owner->pi_lock);\n",
      "\t}\n",
      "\n",
      "\tpi_state->owner = NULL;\n",
      "\t\tatomic_set(&pi_state->refcount);\n",
      "\t\t\tthis->pi_state = pi_state;\n",
      "\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex.wait_lock);\n",
      "\trt_mutex_unlock(&rnp->boost_mtx);  /* Then keep lockdep happy. */\n",
      "\n",
      "\treturn ACCESS_ONCE(file_inode(filp)->i_private);\n",
      "}\n",
      "\n",
      "extern struct mutex trace_types_lock;\n",
      "\n",
      "extern int trace_array_get(struct trace_array *tr = &global_trace;\n",
      "\tint ret;\n",
      "\n",
      "\tret = kstrtoul_from_user(ubuf, cnt, 10, &val);\n",
      "\tif (ret)\n",
      "\t\treturn ret;\n",
      "\n",
      "\tftrace_start_up--;\n",
      "\t/*\n",
      "\t * Just warn in case of unbalance, no need to kill ftrace, it's not\n",
      "\t * critical but the ftrace_call callers may be never nopped again after\n",
      "\t * further ftrace uses.\n",
      "\t */\n",
      "\tWARN_ON_ONCE(!list_empty(&worker->entry) &&\n",
      "\t\t\t (worker->hentry.next || worker->hentry.pprev)))\n",
      "\t\treturn;\n",
      "\n",
      "\t/* can't use worker_set_flags(), also called from create_worker() */\n",
      "\tworker->flags |= WORKER_UNBOUND;\n",
      "\n",
      "\t\tpool->flags |= POOL_DISASSOCIATED;\n",
      "\n",
      "\tfor_each_pool_worker(worker, pool)\t\t\t\t\\\n",
      "\tlist_for_each_entry_continue(file, &tr->events, list) {\n",
      "\t\tif (tp_event->event.type == event_id &&\n",
      "\t\t    tp_event->class && tp_event->class->reg(tp_event, TRACE_REG_PERF_REGISTER, NULL);\n",
      "\tif (ret)\n",
      "\t\tgoto err_flags;\n",
      "\n",
      "\ttu->consumer.filter = filter;\n",
      "\tret = uprobe_register(tu->inode, tu->offset, &tu->consumer, true);\n",
      "\t\tif (err)\n",
      "\t\t\tuprobe_perf_close(tu, event);\n",
      "\t}\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "DECLARE_RWSEM(uts_sem);\n",
      "\n",
      "#ifdef COMPAT_UTS_MACHINE\n",
      "#define override_architecture(name))\n",
      "\t\terrno = -EFAULT;\n",
      "\tup_\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, 20, nletters=5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order 10 is pretty much junk. In order 15 things sort-of make sense, but we jump abruptly between the \n",
    "and by order 20 we are doing quite nicely -- but are far from keeping good indentation and brackets. \n",
    "\n",
    "How could we? we do not have the memory, and these things are not modeled at all. While we could quite easily enrich our model to support also keeping track of brackets and indentation (by adding information such as \"have I seen ( but not )\" to the conditioning history), this requires extra work, non-trivial human reasoning, and will make the model significantly more complex. \n",
    "\n",
    "Neural networks, on the other hand, seemed to have just learn it on its own. And that's impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a head to head comparison between n-gram LMs and a neural network that uses trigram word embeddings as input to predict the next token. \n",
    "\n",
    "Notice that the model is very similar to the word2vec continuous bag of words (CBOW) model except that instead of a masked token surrounded by the tokens used to predict the masked token, instead we predict the next token (as if it was masked) using the left to right context. Both models use n-gram word embeddings but n-gram LMs use a multi-layer model instead of a single layer like word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emmalyiah\n",
      "arie\n",
      "miscotter\n",
      "khia\n",
      "zel\n",
      "zaylen\n",
      "ceren\n",
      "tuley\n",
      "riya\n",
      "elle\n",
      "kano\n",
      "malillyanayah\n",
      "zsofiyya\n",
      "neh\n",
      "elistaro\n",
      "kiyah\n",
      "kah\n",
      "batisaary\n",
      "stroyalayns\n",
      "filia\n",
      "leg\n",
      "helyner\n",
      "rovian\n",
      "febena\n",
      "johaan\n",
      "enedyn\n",
      "carshir\n",
      "abishawn\n",
      "jentriousseta\n",
      "maizajana\n",
      "adharlos\n",
      "stabell\n",
      "prinsley\n",
      "drey\n",
      "jermana\n",
      "lisseelin\n",
      "chanell\n",
      "kadeisha\n",
      "sojoledgermiya\n",
      "lon\n",
      "jola\n",
      "zamaleya\n",
      "adeli\n",
      "jenia\n",
      "faylon\n",
      "vadisyn\n",
      "javaremari\n",
      "selessy\n",
      "pres\n",
      "badina\n",
      "raskilen\n",
      "asir\n",
      "aadilee\n",
      "javienne\n",
      "ausayla\n",
      "calle\n",
      "alvantwan\n",
      "avraj\n",
      "zaevyanal\n",
      "mylen\n",
      "wojcie\n",
      "maizaelius\n",
      "samsamyah\n",
      "shious\n",
      "maha\n",
      "weston\n",
      "ryel\n",
      "devannoxley\n",
      "timonne\n",
      "christon\n",
      "khalyzah\n",
      "ellah\n",
      "kazelle\n",
      "mishaun\n",
      "drya\n",
      "amario\n",
      "nuh\n",
      "orianiya\n",
      "maedore\n",
      "uzziel\n",
      "kelbinyelle\n",
      "kair\n",
      "ryehinah\n",
      "han\n",
      "durelle\n",
      "uriebe\n",
      "cha\n",
      "mayia\n",
      "aylen\n",
      "caelynn\n",
      "kelvin\n",
      "isa\n",
      "tafsandier\n",
      "dani\n",
      "courtney\n",
      "natehilderiatthaniya\n",
      "dalyx\n",
      "len\n",
      "hedy\n",
      "mahelik\n",
      "artarley\n",
      "lee\n",
      "abdulla\n",
      "paulamis\n",
      "paul\n",
      "assian\n",
      "kateh\n",
      "melrahirah\n",
      "lei\n",
      "ajit\n",
      "awaz\n",
      "camatavi\n",
      "shranzaryiah\n",
      "irwani\n",
      "kharmaniel\n",
      "rubison\n",
      "niz\n",
      "yazlyn\n",
      "hasey\n",
      "jahli\n",
      "naya\n",
      "naclarden\n",
      "conson\n",
      "blayzaheem\n",
      "tymir\n",
      "candil\n",
      "lawsyn\n",
      "jamiyana\n",
      "calle\n",
      "jazmino\n",
      "gracious\n",
      "everlyn\n",
      "ellan\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"names.txt\", order=3)\n",
    "print(generate_text(lm, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        font-size: 110%;\n",
       "        margin-left:5% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 110%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "            font-size: 110%;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../css/notebook.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
