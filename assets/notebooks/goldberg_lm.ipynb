{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The unreasonable effectiveness of Character-level Language Models\n",
    "## (and why RNNs are still cool)\n",
    "\n",
    "### [Yoav Goldberg](http://www.cs.biu.ac.il/~yogo)\n",
    "\n",
    "RNNs, LSTMs and Deep Learning are all the rage, and a recent [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy is doing a great job explaining what these models are and how to train them.\n",
    "It also provides some very impressive results of what they are capable of.  This is a great post, and if you are interested in natural language, machine learning or neural networks you should definitely read it. \n",
    "\n",
    "Go read it now, then come back here. \n",
    "\n",
    "You're back? good. Impressive stuff, huh? How could the network learn to immitate the input like that?\n",
    "Indeed. I was quite impressed as well.\n",
    "\n",
    "However, it feels to me that most readers of the post are impressed by the wrong reasons.\n",
    "This is because they are not familiar with **unsmoothed maximum-liklihood character level language models** and their unreasonable effectiveness at generating rather convincing natural language outputs.\n",
    "\n",
    "In what follows I will briefly describe these character-level maximum-likelihood langauge models, which are much less magical than RNNs and LSTMs, and show that they too can produce a rather convincing Shakespearean prose. I will also show about 30 lines of python code that take care of both training the model and generating the output. Compared to this baseline, the RNNs may seem somehwat less impressive. So why was I impressed? I will explain this too, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Maximum Likelihood Character Level Language Model \n",
    "\n",
    "The name is quite long, but the idea is very simple.  We want a model whose job is to guess the next character based on the previous $n$ letters. For example, having seen `ello`, the next characer is likely to be either a commma or space (if we assume is is the end of the word \"hello\"), or the letter `w` if we believe we are in the middle of the word \"mellow\". Humans are quite good at this, but of course seeing a larger history makes things easier (if we were to see 5 letters instead of 4, the choice between space and `w` would have been much easier).\n",
    "\n",
    "We will call $n$, the number of letters we need to guess based on, the _order_ of the language model.\n",
    "\n",
    "RNNs and LSTMs can potentially learn infinite-order language model (they guess the next character based on a \"state\" which supposedly encode all the previous history). We here will restrict ourselves to a fixed-order language model.\n",
    "\n",
    "So, we are seeing $n$ letters, and need to guess the $n+1$th one. We are also given a large-ish amount of text (say, all of Shakespear works) that we can use. How would we go about solving this task?\n",
    "\n",
    "Mathematically, we would like to learn a function $P(c | h)$. Here, $c$ is a character, $h$ is a $n$-letters history, and $P(c|h)$ stands for how likely is it to see $c$ after we've seen $h$.\n",
    "\n",
    "Perhaps the simplest approach would be to just count and divide (a.k.a **maximum likelihood estimates**). We will count the number of times each letter $c'$ appeared after $h$, and divide by the total numbers of letters appearing after $h$. The **unsmoothed** part means that if we did not see a given letter following $h$, we will just give it a probability of zero.\n",
    "\n",
    "And that's all there is to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code\n",
    "Here is the code for training the model. `fname` is a file to read the characters from. `order` is the history size to consult. Note that we pad the data with leading `~` so that we also learn how to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import *\n",
    "\n",
    "def train_char_lm(fname, order=4):\n",
    "    data = open(fname).read()\n",
    "    lm = defaultdict(Counter)\n",
    "    pad = \"~\" * order\n",
    "    data = pad + data\n",
    "    for i in range(len(data)-order):\n",
    "        history, char = data[i:i+order], data[i+order]\n",
    "        lm[history][char]+=1\n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c,cnt/s) for c,cnt in counter.items()]\n",
    "    outlm = {hist:normalize(chars) for hist, chars in lm.items()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it on Andrej's Shakespears's text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-02 08:57:06--  http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt [following]\n",
      "--2024-10-02 08:57:09--  https://www.cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving www.cs.stanford.edu (www.cs.stanford.edu)... 23.216.154.115, 23.216.154.123\n",
      "Connecting to www.cs.stanford.edu (www.cs.stanford.edu)|23.216.154.115|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2024-10-02 08:57:11 ERROR 404: Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now let's do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 0.045532157085941945),\n",
       " (' ', 0.5156516789982926),\n",
       " ('c', 0.0443938531587934),\n",
       " ('.', 0.035287421741605006),\n",
       " (',', 0.21457029026750143),\n",
       " (';', 0.02902675014228799),\n",
       " (':', 0.017643710870802503),\n",
       " ('!', 0.00796812749003984),\n",
       " ('\\n', 0.02390438247011952),\n",
       " (\"'\", 0.006260671599317018),\n",
       " ('s', 0.03414911781445646),\n",
       " ('o', 0.0005691519635742744),\n",
       " ('i', 0.021627774615822423),\n",
       " ('-', 0.0005691519635742744),\n",
       " ('t', 0.0022766078542970974),\n",
       " ('e', 0.0005691519635742744)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['then']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 1.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['Firs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 0.09550561797752809),\n",
       " ('f', 0.011235955056179775),\n",
       " ('i', 0.016853932584269662),\n",
       " ('t', 0.05377207062600321),\n",
       " ('u', 0.0016051364365971107),\n",
       " ('S', 0.16292134831460675),\n",
       " ('h', 0.019261637239165328),\n",
       " ('s', 0.03290529695024077),\n",
       " ('R', 0.0008025682182985554),\n",
       " ('b', 0.024879614767255216),\n",
       " ('c', 0.012841091492776886),\n",
       " ('O', 0.018459069020866775),\n",
       " ('w', 0.024077046548956663),\n",
       " ('a', 0.02247191011235955),\n",
       " ('m', 0.02247191011235955),\n",
       " ('n', 0.020064205457463884),\n",
       " ('I', 0.009630818619582664),\n",
       " ('L', 0.10674157303370786),\n",
       " ('M', 0.0593900481540931),\n",
       " ('l', 0.01043338683788122),\n",
       " ('o', 0.030497592295345103),\n",
       " ('H', 0.0040128410914927765),\n",
       " ('d', 0.015248796147672551),\n",
       " ('W', 0.033707865168539325),\n",
       " ('K', 0.008025682182985553),\n",
       " ('q', 0.0016051364365971107),\n",
       " ('G', 0.0898876404494382),\n",
       " ('g', 0.011235955056179775),\n",
       " ('k', 0.0040128410914927765),\n",
       " ('e', 0.0032102728731942215),\n",
       " ('y', 0.002407704654895666),\n",
       " ('r', 0.0072231139646869984),\n",
       " ('p', 0.00882825040128411),\n",
       " ('A', 0.0056179775280898875),\n",
       " ('P', 0.014446227929373997),\n",
       " ('F', 0.012038523274478331),\n",
       " ('v', 0.002407704654895666),\n",
       " ('T', 0.0032102728731942215),\n",
       " ('D', 0.0032102728731942215),\n",
       " ('B', 0.009630818619582664),\n",
       " ('N', 0.0008025682182985554),\n",
       " (\"'\", 0.0008025682182985554),\n",
       " ('E', 0.0016051364365971107)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['rst ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `ello` is followed by either space, punctuation or `w` (or `r`, `u`, `n`), `Firs` is pretty much deterministic, and the word following `ist ` can start with pretty much every letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating from the model\n",
    "Generating is also very simple. To generate a letter, we will take the history, look at the last $order$ characteters, and then sample a random letter based on the corresponding distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def generate_letter(lm, history, order):\n",
    "        history = history[-order:]\n",
    "        dist = lm[history]\n",
    "        x = random()\n",
    "        for c,v in dist:\n",
    "            x = x - v\n",
    "            if x <= 0: return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a passage of $k$ characters, we just seed it with the initial history and run letter generation in a loop, updating the history at each turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm, order, nletters=1000):\n",
    "    history = \"~\" * order\n",
    "    out = []\n",
    "    for i in range(nletters):\n",
    "        c = generate_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        out.append(c)\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Shakespeare from different order models\n",
    "\n",
    "Let's try to generate text based on different language-model orders. Let's start with something silly:\n",
    "\n",
    "### order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fifick's se, clesse; leave a knot im of\n",
      "yes will theithear of Capprinjus mas the\n",
      "HELING Lordearing!\n",
      "Ten by I\n",
      "anchis an her, a gret muc, and stunmad!\n",
      "HARING Lorthis the dem-se chatherem, wixem,\n",
      "Whis thentlea, bable sind, be anmaressil.\n",
      "\n",
      "Cap,\n",
      "th trauddre.\n",
      "\n",
      "So hines. Ther mise\n",
      "Thes; athe my for cond arm suld wed, and ve the'ld setim my peaccappeaf the mor\n",
      "And al?\n",
      "\n",
      "Bries any sh it to her'd vill ow ther's See, a thalre ford, in you wer.\n",
      "\n",
      "Do, hinglass? nork whicas,--\n",
      "\n",
      "Gen innere. Chat sex orry?\n",
      "\n",
      "Lor th!\n",
      "\n",
      "Go of no eave\n",
      "caugh, of a jestlege.\n",
      "\n",
      "Yetenceress,\n",
      "BER:\n",
      "Ame hime travill.\n",
      "O'ert ther:\n",
      "Thumsen no singthenter like I have godgeard:\n",
      "Weret hentakeed, affishou wild thingen eve mayse doisdo Rome?\n",
      "Givererear,\n",
      "SUS:\n",
      "Them nown a wit lius' this fre fown\n",
      "ashe cre neve chou pler go IV:\n",
      "Comme ke ENRY Bin wivent, he sper in.\n",
      "\n",
      "Che lialtely yought swor ettervand bithes,\n",
      "Nor and hation he now\n",
      "OLUS:\n",
      "Firan leas deadvager ticer sets up sublorell beeponew o's asue\n",
      "wileart chan:\n",
      "Sill do thy the farry re and hate\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=2)\n",
    "print(generate_text(lm, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so great.. but what if we increase the order to 4?\n",
    "\n",
    "### order 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First not, the be devously tristing to see\n",
      "him scape,\n",
      "when\n",
      "embrace to seen ther.\n",
      "\n",
      "SOMERSET:\n",
      "Fare though unfold;\n",
      "My same,\n",
      "these and grace, my grund thee,\n",
      "When she he wear at thou,\n",
      "There hearthly put\n",
      "My father spoil: heart of back offician known hopes; to that's, ere hero is the naked upsider are to-night 'tis a son:\n",
      "And advance: if heral, alter'd and hath smathersity.\n",
      "\n",
      "FALSTAFF:\n",
      "Truly, with and low thou must is have not with mass, halt the pale.\n",
      "\n",
      "LAERTES:\n",
      "Decoctus.\n",
      "How her thin claiments; 'tis most never devotion we shall I straitors legious suitor a greath me.\n",
      "Now, cheerful press' from my father. What's courtesy\n",
      "Thou be fie, and brief; often my soul\n",
      "The muster'd name;\n",
      "If it to fear me tongue will you not few will.\n",
      "\n",
      "BIRON:\n",
      "All's banner reason. Haply my peace!\n",
      "\n",
      "LONGAVILLE:\n",
      "I shallow, and,\n",
      "That were like of othereof his battle devils of this flesh powers, as I; 'tis not like the a more valouds,\n",
      "I wilt some upon this, which heart.\n",
      "\n",
      "TROILUS:\n",
      "Fly not needs hadst thus.\n",
      "\n",
      "COUNTESS OF SYRACUSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First beat me sparing eye\n",
      "Of old, rides in this is our proclaim as his parce his wooing I'ld remerchief\n",
      "Is all finess.\n",
      "\n",
      "DUCHESS FORD:\n",
      "Well,\n",
      "By signess,\n",
      "To trod of though now! are of France: you hither what permioner thy grace?\n",
      "\n",
      "EDWARD:\n",
      "What you forgot?\n",
      "\n",
      "AENEAS:\n",
      "What alongst the asleep peace, braid the throwns; what defeature was line\n",
      "The false days,\n",
      "either the prime anger.\n",
      "\n",
      "CHARD III:\n",
      "A father\n",
      "now now silver moody counseeing become approviden make to figs.\n",
      "Unless he no offendering but ta? do deputy by heart? She less exhales. Coming every time and tend mightness,\n",
      "That thus do no other villain, she was lying\n",
      "Cuts of the crown inful type of my night,\n",
      "And e'er and\n",
      "almost of it who hast,\n",
      "Were eye heart;\n",
      "Becomes to bade his son,--here?\n",
      "\n",
      "LUCIUS:\n",
      "Opens have, this mortime me; and fate you.\n",
      "\n",
      "BEATRICE:\n",
      "It stay lie\n",
      "On embosses, from his sound and elegiant he would not be whose. I have leasier ladies his is at utter'd,\n",
      "One cold. O love's deer?\n",
      "\n",
      "DEMETRIUS:\n",
      "'Tis voices have here\n",
      "a man's lodge in it \n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already quite reasonable, and reads like English. Just 4 letters history! What if we increase it to 7?\n",
    "\n",
    "### order 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "O noble nature native English Henry Bolingbroke\n",
      "Into some paper.\n",
      "\n",
      "EDMUND:\n",
      "If it come to shame.\n",
      "\n",
      "PROTEUS:\n",
      "O, throw away twelvemonth's end\n",
      "I'll peach for you,\n",
      "Though I know you love me this words\n",
      "He scatters\n",
      "Point again,\n",
      "He came early welcome: to Aufidius, welcome home?' quoth he. 'You do you needest him take't of leaping in the tranquil mind! Shall we respect\n",
      "For what? let's hie!\n",
      "\n",
      "BASTARD:\n",
      "She's a verse the last to his come to us,\n",
      "The people were my horses,\n",
      "Where some reason is, she uses of his play\n",
      "is the next for me?\n",
      "\n",
      "PROTEUS:\n",
      "You are too long;\n",
      "But pay me the gods had mustachio purple with iteration of this fortune's womb,\n",
      "That judgment her: welcome from the theatre, whereof is always of villany should love these ears of prison, in any thing?\n",
      "\n",
      "KING JOHN:\n",
      "We from their fortune him against sworn true noblest Rome,\n",
      "Or bitterest.\n",
      "\n",
      "GADSHILL:\n",
      "As well again else. Met'st thou farthest by his better guest; so he will not be seen him that your names?\n",
      "Arm, arm, my lord.\n",
      "\n",
      "AGAMEMNON\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=7)\n",
    "print(generate_text(lm, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Marry, this is thine and their merits and our crimes would prevail\n",
      "Under the cool and tempest of my eyes.\n",
      "\n",
      "THESEUS:\n",
      "What are you here, sir, and welcome! I have a pilot's thumb,\n",
      "Wreck'd as homeward he did contend\n",
      "Which is a comforter.\n",
      "\n",
      "ANTONIO:\n",
      "Alas the heavens,\n",
      "Cut short all intermingle every thing I have done well in his perfect woman, she is\n",
      "indeed more than can the substance into that fair prayer\n",
      "To soften Angelo: and that's myself,\n",
      "The gracious.\n",
      "\n",
      "ARCHBISHOP OF YORK:\n",
      "I had a wound her honourably.\n",
      "So call thee Caesar now,\n",
      "No humble suppliant may\n",
      "But beg one favour and\n",
      "for a week; for the goose came out of love in't.\n",
      "\n",
      "ORLANDO:\n",
      "Nor shall it thee,\n",
      "So long attended with the Duke of Burgundy!\n",
      "\n",
      "BURGUNDY:\n",
      "What wilt thou help'st me not?\n",
      "By heaven, so she could speak with me; Lavinia, let me kiss my sovereignly being honour into lust, to take this poor mad soul; and she is\n",
      "painted also with a white beard? a decreasing leg? an\n",
      "increasing vine!\n",
      "\n",
      "BELARIUS:\n",
      "What's the business put \n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=10)\n",
    "print(generate_text(lm, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works pretty well\n",
    "\n",
    "With an order of 4, we already get quite reasonable results. Increasing the order to 7 (~word and a half of history) or 10 (~two short words of history) already gets us quite passable Shakepearan text. I'd say it is on par with the examples in Andrej's post. And how simple and un-mystical the model is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So why am I impressed with the neural networks after all?\n",
    "\n",
    "Generating English a character at a time -- not so impressive in my view. The NN needs to learn the previous $n$ letters, for a rather small $n$, and that's it. \n",
    "\n",
    "However, the code-generation example is very impressive. Why? because of the context awareness. Note that in all of the posted examples, the code is well indented, the braces and brackets are correctly nested, and even the comments start and end correctly. This is not something that can be achieved by simply looking at the previous $n$ letters. \n",
    "\n",
    "If the examples are not cherry-picked, and the output is generally that nice, then the NN did learn something not trivial at all.\n",
    "\n",
    "Just for the fun of it, let's see what our simple language model does with the linux-kernel code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-02 08:57:25--  http://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt [following]\n",
      "--2024-10-02 08:57:27--  https://www.cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt\n",
      "Resolving www.cs.stanford.edu (www.cs.stanford.edu)... 23.216.154.123, 23.216.154.115\n",
      "Connecting to www.cs.stanford.edu (www.cs.stanford.edu)|23.216.154.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2024-10-02 08:57:28 ERROR 404: Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/sort.h>\n",
      "\n",
      "#include <linux/irq_work.h>\n",
      "#include <linux/sysctl.h>\n",
      "#include <linux/threads.h>\n",
      "#include <linux/atomic.h>\n",
      "#include <linux/string.h>\n",
      "#include <linux/cred.h>\n",
      "#include <linux/init.h>\n",
      "#include <linux/seq_file.h>\n",
      "#include <linux/interrupt.. Legacy)\n",
      "\t */\n",
      "\tif (!param)\n",
      "\t\tgoto out;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tret = __trace_graph_ent,\tgraph_ent\t\t\t= *trace;\n",
      "\tint ret;\n",
      "\n",
      "\tmutex_unlock(&tu->filter.nr_systemwide--;\n",
      "\t\tdone = tu->filter.nr_systemwide)\n",
      "\t\treturn 0;\n",
      "}\n",
      "\n",
      "/**\n",
      " * ptrace_stop(void *data;\n",
      "\tint cpu = (long)hcpu;\n",
      "\n",
      "\tswitch (key->both.offset |= FUT_OFF_MMSHARED:\n",
      "\t\tfutex_get_mm(union futex_keys that hash to the same jiffy.\n",
      " */\n",
      "static void perf_event_header\theader;\n",
      "\n",
      "\t\tu32\t\t\t\tpid;\n",
      "\t\tu32\t\t\t\ttid;\n",
      "};\n",
      "\n",
      "static void register state */\n",
      "\t\tif (dattr) {\n",
      "\t\t\t*dattr = SD_ATTR_INIT;\n",
      "\t\t\tupdate_group_times(event);\n",
      "\t\trt_mutex_unlock(&kprobe_mutex);\n",
      "\n",
      "\t/*\n",
      "\t * rb->aux_mmap_count))\n",
      "\t\tgoto out_free;\n",
      "\t}\n",
      "\tcurrent->flags & FAULT_FLAG_WRITE);\n",
      "\tup_read(&uts_sem);\n",
      "\tu = utsname()\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=10)\n",
    "print(generate_text(lm, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/time/tick-broadcast-hrtimer.c\n",
      " * This file emulates a local clock event devices which handle everything in page size chunks ensure\n",
      "\t * the destination addresses\n",
      "\t * through very weird things can happen\n",
      "\t * if the module is unloaded, and then by giving the lock_torture_stats_print();\n",
      "\t\ttorture_shutdown task started\");\n",
      "\tdo {\n",
      "\t\tschedule_timeout_interruptible(1);\n",
      "\t}\n",
      "\tsmp_mb(); /* matches sched_clock_init() */\n",
      "\n",
      "\tif (!sched_clock_irqtime) {\n",
      "\t\tirqtime_account_hi_update(void)\n",
      "{\n",
      "\tktime_t period;\n",
      "\n",
      "\twrite_seqlock(&tsk->vtime_seqlock);\n",
      "}\n",
      "\n",
      "void * __weak arch_kexec_kernel_verify_sig(image, image->kernel_buf_len);\n",
      "\n",
      "\tif (ret < 0)\n",
      "\t\terrors++;\n",
      "\n",
      "\tnum_tests++;\n",
      "\tret = test_kprobe();\n",
      "\tif (ret < 0)\n",
      "\t\tgoto out_balanced;\n",
      "\n",
      "\tif (env->idle != CPU_NOT_IDLE) &&\n",
      "\t    likely(p->policy != SCHED_NORMAL && policy != SCHED_DEADLINE task.\n",
      " *\n",
      " * Only the static values are converted to jiffies when they are still\n",
      "\t * active. Clear the pending bitmasks, but must still be cleared in our caller bc CLONE_THRE\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=15)\n",
    "print(generate_text(lm, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/chip.c\n",
      " *\n",
      " * Copyright 2003-2007 Red Hat Inc., Durham, North Carolina.\n",
      " * Copyright 2005 Hewlett-Packard Development Company, L.P.\n",
      " * Copyright (C) 2004-2006 Tom Rini <trini@kernel.crashing.org>\n",
      " * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.\n",
      " * Copyright (c) 2003 Patrick Mochel\n",
      " * Copyright (c) 2009 Wind River Systems, Inc.  All Rights Reserved.\n",
      " * Written by David Howells (dhowells@redhat.com)\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful,\n",
      " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU General Public License\n",
      " *  along with this program; if not, you can access it online at\n",
      " * http://www.gnu.org/licenses/gpl-2.0.html.\n",
      " *\n",
      " * Copyright (c) 2001   David Howells (dhowells@redhat.com).\n",
      " * - Derived partially from idea by Andrea Arcangeli <andrea@suse.de>\n",
      " * - Derived also from comments by Linus\n",
      " */\n",
      "#include <linux/swap.h>\n",
      "#include <linux/cpu.h>\n",
      "#i\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=20)\n",
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/autoprobe.c\n",
      " *\n",
      " * Copyright (C) IBM Corporation, 2014\n",
      " *\n",
      " * Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>\n",
      " */\n",
      "\n",
      "#include <linux/module.h>\t/* for MODULE_NAME_LEN via KSYM_SYMBOL_LEN */\n",
      "#include <linux/clocksource.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/mm.h>\n",
      "#include <linux/percpu.h>\n",
      "#include <linux/mount.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/kdb.h>\n",
      "#include <linux/module.h>\n",
      "\n",
      "#include <asm/uaccess.h>\n",
      "\n",
      "/*\n",
      " * mutex protecting text section modification (dynamic code patching).\n",
      " * some users need to sleep (allocating memory...) while they hold this lock.\n",
      " *\n",
      " * NOT exported to modules - patching kernel text is a really delicate matter.\n",
      " */\n",
      "DEFINE_MUTEX(trace_types_lock);\n",
      "\n",
      "\treturn ret;\n",
      "}\n",
      "\n",
      "static int update_cpumask(struct cpuset *cs, nodemask_t *new_mems,\n",
      "\t\t     bool cpus_updated, bool mems_updated)\n",
      "{\n",
      "\tbool is_empty;\n",
      "\n",
      "\tspin_lock_irq(&callback_lock);\n",
      "\t\tif (!on_dfl)\n",
      "\t\t\tcpumask_copy(top_cpuset.effective_mems = node_states[N_MEMORY].\n",
      " * Call this routine anyti\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/autoprobe.c\n",
      " *\n",
      " * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar\n",
      " * Copyright(C) 2005-2007, Red Hat, Inc., Ingo Molnar <mingo@redhat.com>\n",
      " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>\n",
      " *  Copyright (C) 2004 Pavel Machek <pavel@ucw.cz>\n",
      " * Copyright (C) 2012 Dario Faggioli <raistlin@linux.it>,\n",
      " *                                       /* 5 bit base 2 exponent, 20 bits mantissa.\n",
      " * The leading bit of the mantissa is not stored, but implied for\n",
      " * non-zero exponents.\n",
      " * Largest encodable value is 50 bits.\n",
      " */\n",
      "\n",
      "#define MANTSIZE2       20                          |\n",
      " *      |                                         ----\\n\");\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int trace_selftest_startup_function_graph(struct tracer *trace, struct trace_array *tr)\n",
      "{\n",
      "\tstart_branch_trace(tr);\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int tk_debug_show_sleep_time, NULL);\n",
      "}\n",
      "\n",
      "static const struct file_operations proc_cgroupstats_operations);\n",
      "\treturn 0;\n",
      "}\n",
      "device_initcall(audit_watch_init);\n",
      "/* Copyright (c) 2011, Google, Inc.\n",
      " *\n",
      " * This software is licensed under the terms of the GNU General Public License\n",
      " * along with this program; if not, you can access it online at\n",
      " * http://www.gnu.org/licenses/>.\n",
      " */\n",
      "\n",
      "#define pr_fmt(fmt)  \"irq: \" fmt\n",
      "\n",
      "#include <linux/ctype.h>\n",
      "#include <linux/kernel.h>\n",
      "#include <linux/export.h>\n",
      "#include <linux/alarmtimer.h>\n",
      "#include <linux/export.h>\n",
      "#include <linux/highmem.h>\n",
      "#include <linux/mutex.h>\n",
      "#include <linux/initrd.h>\n",
      "#include <linux/sched.h>\n",
      "#include <linux/mm.h>\n",
      "#include <linux/irq_work.h>\n",
      "#include <linux/compiler.h>\n",
      "\n",
      "#include \"tick-internal.h\"\n",
      "\n",
      "/* The registered clock event devices */\n",
      "static ssize_t sysfs_unbind_clocksource(struct device *dev, struct device_attribute *attr,\n",
      "\t\t\t\t  const char *buf, size_t nbytes, loff_t off)\n",
      "{\n",
      "\tbool freeze;\n",
      "\n",
      "\tbuf = strstrip(buf);\n",
      "\n",
      "\tif (strcmp(buf, freezer_state_strs(0)) == 0)\n",
      "\t\tfreeze = false;\n",
      "\telse if (strcmp(buf, freezer_state_strs(css_freezer(css)->state));\n",
      "\tseq_putc(m, '\\n');\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static struct task_struct *from, struct task_struct *p;\n",
      "\n",
      "\tif (!futex_cmpxchg_enabled)\n",
      "\t\treturn -ENODEV;\n",
      "\n",
      "\tif (event->group_leader != event) {\n",
      "\t\t\tgroup_sched_out(event, cpuctx, ctx))\n",
      "\t\t\t\tcan_add_hw = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "\n",
      "static void nohz_full_kick_ipi(void *info)\n",
      "{\n",
      "\t__tick_nohz_full_check(void)\n",
      "{\n",
      "\tstruct task_struct *p,\n",
      "\t       struct cpumask *new_mask)\n",
      "{\n",
      "\tstruct rq *rq;\n",
      "\tint weight;\n",
      "\n",
      "\tBUG_ON(!rt_task(p));\n",
      "\n",
      "\treturn p;\n",
      "}\n",
      "\n",
      "/*\n",
      " * See if the non running -deadline tasks on this rq\n",
      " * can be sent to some other CPU where they can preempt\n",
      " * and start executing.\n",
      " */\n",
      "static int rcu_boost(struct rcu_node *rnp)\n",
      "{\n",
      "\tstruct task_struct *p)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\n",
      " again:\n",
      "\traw_spin_lock_irqsave);\n",
      "#endif\n",
      "\n",
      "#ifndef CONFIG_INLINE_READ_LOCK_IRQSAVE\n",
      "unsigned long __lockfunc __raw_##op##_lock_irq(locktype##_t *lock)\t\t\t\\\n",
      "{\t\t\t\t\t\t\t\t\t\\\n",
      "\tfor (;;) {\t\t\t\t\t\t\t\\\n",
      "\t\tpreempt_disable();\n",
      "\tif (waitqueue_active(&area->wq))\n",
      "\t\t\twake_up(&area->wq);\n",
      "\n",
      "\t\ttsk->utask->xol_vaddr;\n",
      "\tif (unlikely(!slot_addr))\n",
      "\t\treturn;\n",
      "\n",
      "\tarea = tsk->mm->uprobes_state.xol_area)\n",
      "\t\tgoto fail;\n",
      "\n",
      "\tif (!area->vaddr) {\n",
      "\t\t/* Try to map as high as possible, this is only a hint. */\n",
      "\t\tarea->vaddr = get_unmapped_area(NULL, TASK_SIZE - PAGE_SIZE,\n",
      "\t\t\t\t\t\tPAGE_SIZE, 0, 0);\n",
      "\t\tif (area->vaddr & ~PAGE_MASK) {\n",
      "\t\t\tret = area->vaddr;\n",
      "\t\t\tgoto fail;\n",
      "\t\t}\n",
      "\t}\n",
      "\tput_online_cpus();\n",
      "\n",
      "\tBLOCKING_INIT_NOTIFIER_HEAD(&pinst->cpumask_change_notifier,\n",
      "\t\t\t\t\t\tnblock);\n",
      "}\n",
      "EXPORT_SYMBOL(_raw_spin_trylock_bh);\n",
      "#endif\n",
      "\n",
      "#ifndef CONFIG_INLINE_WRITE_LOCK\n",
      "void __lockfunc _raw_write_trylock(rwlock_t *lock)\n",
      "{\n",
      "\t__raw_spin_unlock_irq(&pi_state->owner->pi_lock);\n",
      "\t}\n",
      "\n",
      "\tpi_state->owner = NULL;\n",
      "\t\tatomic_set(&pi_state->refcount);\n",
      "\t\t\tthis->pi_state = pi_state;\n",
      "\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex.wait_lock);\n",
      "\trt_mutex_unlock(&rnp->boost_mtx);  /* Then keep lockdep happy. */\n",
      "\n",
      "\treturn ACCESS_ONCE(file_inode(filp)->i_private);\n",
      "}\n",
      "\n",
      "extern struct mutex trace_types_lock;\n",
      "\n",
      "extern int trace_array_get(struct trace_array *tr = &global_trace;\n",
      "\tint ret;\n",
      "\n",
      "\tret = kstrtoul_from_user(ubuf, cnt, 10, &val);\n",
      "\tif (ret)\n",
      "\t\treturn ret;\n",
      "\n",
      "\tftrace_start_up--;\n",
      "\t/*\n",
      "\t * Just warn in case of unbalance, no need to kill ftrace, it's not\n",
      "\t * critical but the ftrace_call callers may be never nopped again after\n",
      "\t * further ftrace uses.\n",
      "\t */\n",
      "\tWARN_ON_ONCE(!list_empty(&worker->entry) &&\n",
      "\t\t\t (worker->hentry.next || worker->hentry.pprev)))\n",
      "\t\treturn;\n",
      "\n",
      "\t/* can't use worker_set_flags(), also called from create_worker() */\n",
      "\tworker->flags |= WORKER_UNBOUND;\n",
      "\n",
      "\t\tpool->flags |= POOL_DISASSOCIATED;\n",
      "\n",
      "\tfor_each_pool_worker(worker, pool)\t\t\t\t\\\n",
      "\tlist_for_each_entry_continue(file, &tr->events, list) {\n",
      "\t\tif (tp_event->event.type == event_id &&\n",
      "\t\t    tp_event->class && tp_event->class->reg(tp_event, TRACE_REG_PERF_REGISTER, NULL);\n",
      "\tif (ret)\n",
      "\t\tgoto err_flags;\n",
      "\n",
      "\ttu->consumer.filter = filter;\n",
      "\tret = uprobe_register(tu->inode, tu->offset, &tu->consumer, true);\n",
      "\t\tif (err)\n",
      "\t\t\tuprobe_perf_close(tu, event);\n",
      "\t}\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "DECLARE_RWSEM(uts_sem);\n",
      "\n",
      "#ifdef COMPAT_UTS_MACHINE\n",
      "#define override_architecture(name))\n",
      "\t\terrno = -EFAULT;\n",
      "\tup_\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, 20, nletters=5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order 10 is pretty much junk. In order 15 things sort-of make sense, but we jump abruptly between the \n",
    "and by order 20 we are doing quite nicely -- but are far from keeping good indentation and brackets. \n",
    "\n",
    "How could we? we do not have the memory, and these things are not modeled at all. While we could quite easily enrich our model to support also keeping track of brackets and indentation (by adding information such as \"have I seen ( but not )\" to the conditioning history), this requires extra work, non-trivial human reasoning, and will make the model significantly more complex. \n",
    "\n",
    "Neural networks, on the other hand, seemed to have just learn it on its own. And that's impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a head to head comparison between n-gram LMs and a neural network that uses trigram word embeddings as input to predict the next token. \n",
    "\n",
    "Notice that the model is very similar to the word2vec continuous bag of words (CBOW) model except that instead of a masked token surrounded by the tokens used to predict the masked token, instead we predict the next token (as if it was masked) using the left to right context. Both models use n-gram word embeddings but n-gram LMs use a multi-layer model instead of a single layer like word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_char_lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lm \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_char_lm\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(generate_text(lm, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_char_lm' is not defined"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"names.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        font-size: 110%;\n",
       "        margin-left:5% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 110%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "            font-size: 110%;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../css/notebook.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
