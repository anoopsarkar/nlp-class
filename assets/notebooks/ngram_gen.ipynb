{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-67129330b93e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgutenberg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLidstoneProbDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk.model'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.model import *\n",
    "from nltk.probability import LidstoneProbDist\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "class NullDevice():\n",
    "    def write(self, s):\n",
    "        pass\n",
    "\n",
    "use_chars = True\n",
    "\n",
    "#sys.stderr = NullDevice()\n",
    "estimator = lambda fdist, bins: LidstoneProbDist(fdist, 0.02)\n",
    "\n",
    "t = None\n",
    "if use_chars:\n",
    "    t = [ [ c for c in ' '.join(sent) ] for sent in gutenberg.sents('carroll-alice.txt') ]\n",
    "else:\n",
    "    t = [ x for x in gutenberg.sents('carroll-alice.txt') ]\n",
    "\n",
    "def ngram_gen(n, t, len=100):\n",
    "    print(\"\\n%d-gram model\\n---------------\\n\" % (n))\n",
    "    m = NgramModel(n, t, True, True, estimator)\n",
    "    #print m.entropy(\"if you cannot mean what you say then at least say what you mean\".split())\n",
    "    sep = '' if use_chars else ' '\n",
    "    if n == 1:\n",
    "        # there is a bug in nltk NgramModel when n=1. it just produces a sequence of . characters\n",
    "        genstring = sep.join([ m[()].generate() for i in range(len) ])\n",
    "    else:\n",
    "        genstring = sep.join(m.generate(len))\n",
    "    print(genstring)\n",
    "    return genstring\n",
    "\n",
    "genstring_list = [ngram_gen(n, t) for n in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', '),', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', '-', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.'], ['There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', ',', \"'\", 'Oh', 'dear', '!']]\n"
     ]
    }
   ],
   "source": [
    "# Code modified by Anoop Sarkar from original replacement for the NLTK NGramModel by Roger Levy\n",
    "# http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/code/NgramModel.py\n",
    "# http://idiom.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture11/lecture11_ngrams_in_Python.pdf\n",
    "\n",
    "import nltk, random, collections, math\n",
    "from math import log\n",
    "from collections import Counter\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "use_chars = False\n",
    "beginToken = \"<s>\"\n",
    "boundaryToken = \"</s>\"\n",
    "\n",
    "# we can get replicable behavior by initializing the random number generator with random.seed()\n",
    "random.seed(1)\n",
    "\n",
    "train = None\n",
    "if use_chars:\n",
    "    train = [ [ c for c in ' '.join(sent) ] for sent in gutenberg.sents('carroll-alice.txt') ]\n",
    "else:\n",
    "    train = [ x for x in gutenberg.sents('carroll-alice.txt') ]\n",
    "\n",
    "def ngrams(n,sentences,beginToken=beginToken,boundaryToken=boundaryToken,verbose=False):\n",
    "    c = {}\n",
    "    q = []\n",
    "    for i in range(n-1):\n",
    "        q.append(beginToken)\n",
    "    for sentence in sentences:\n",
    "        for w in sentence + [boundaryToken]:\n",
    "            context_gram = stringify_context(q)\n",
    "            #print \"ngrams(w):\", w\n",
    "            #print \"context_gram:\", context_gram\n",
    "            if verbose:\n",
    "                print(q)\n",
    "                print(context_gram)\n",
    "                print(w)\n",
    "            if not context_gram in c:\n",
    "                c[context_gram] = Counter()\n",
    "            c[context_gram][w] += 1\n",
    "            q.pop(0)\n",
    "            q.append(w)\n",
    "    return(c)\n",
    "\n",
    "def stringify_context(context):\n",
    "    return(\" \".join(context))\n",
    "    \n",
    "class NgramModel:\n",
    "    def __init__(self, training_sentences, n=2, smoothing='none',verbose=False):\n",
    "        self.n = n\n",
    "        train = ngrams(n,training_sentences,verbose=verbose)\n",
    "        self.probs = {}\n",
    "        if smoothing=='none':\n",
    "            for context_gram in list(train.keys()):\n",
    "                N = sum(train[context_gram].values())\n",
    "                self.probs[context_gram] = Counter({k:v/N for k,v in list(train[context_gram].items())})\n",
    "                if verbose:\n",
    "                    print([(context_gram,k,v) for k,v in list(train[context_gram].items())])\n",
    "\n",
    "    def prob(self,word,context):\n",
    "        \"\"\"takes a word string and a context which is a list of word strings, and returns the probability of the word\"\"\"\n",
    "        c = stringify_context(context)\n",
    "        return(self.probs[c][word])\n",
    "\n",
    "    def scoreSentence(self,sentence,addBeginToken=False,verbose=False):\n",
    "        result = 0\n",
    "        if len(sentence) < self.n:\n",
    "            return float(\"NaN\")\n",
    "        context = []\n",
    "        if addBeginToken:\n",
    "            for i in range(self.n-1):\n",
    "                context.append(beginToken)\n",
    "        else:\n",
    "            for i in range(self.n-1):\n",
    "                w = sentence.pop(0)\n",
    "                context.append(w)\n",
    "        for w in sentence + [boundaryToken]:\n",
    "            if verbose:\n",
    "                print((context,w,self.prob(w,context)))            \n",
    "            lp = log(self.prob(w,context))\n",
    "            result = result + lp\n",
    "            context.pop(0)\n",
    "            context.append(w)\n",
    "            #context = [w]\n",
    "        return result\n",
    "\n",
    "    def generateSentence(self,verbose=False,goryDetails=False):\n",
    "        context = []\n",
    "        for i in range(self.n-1):\n",
    "            context.append(beginToken)\n",
    "        result = []\n",
    "        w = None\n",
    "        while not w == boundaryToken:\n",
    "            r = random.random() # returns a random float between 0 and 1\n",
    "            x = 0\n",
    "            c = self.probs[stringify_context(context)] # this will be a Counter\n",
    "            for k,v in list(c.items()):\n",
    "                x = x + v\n",
    "                if goryDetails:\n",
    "                    print((r,context,x,k,v))\n",
    "                if x > r: # choose this word\n",
    "                    w = k\n",
    "                    result.append(w)\n",
    "                    context.pop(0)\n",
    "                    context.append(w)\n",
    "                    #context = [w]\n",
    "                    break\n",
    "            if verbose:\n",
    "                print(w)\n",
    "        #result.pop() # drop the boundary token\n",
    "        return result\n",
    "\n",
    "class BigramModel:\n",
    "    def __init__(self, training_sentences, smoothing='none'):\n",
    "        train = ngrams(2,training_sentences)\n",
    "        self.probs = {}\n",
    "        if smoothing=='none':\n",
    "            for context_gram in list(train.keys()):\n",
    "                N = sum(train[context_gram].values())\n",
    "                self.probs[context_gram] = Counter({k:v/N for k,v in list(train[context_gram].items())})\n",
    "\n",
    "    def prob(self,word,context):\n",
    "        \"\"\"takes a word string and a context which is a list of word strings, and returns the probability of the word\"\"\"\n",
    "        c = stringify_context(context)\n",
    "        return(self.probs[c][word])\n",
    "\n",
    "    def scoreSentence(self,sentence,verbose=False):\n",
    "        context = [boundaryToken]\n",
    "        result = 0\n",
    "        for w in sentence + [boundaryToken]:\n",
    "            lp = log(self.prob(w,context))\n",
    "            result = result + lp\n",
    "            if verbose:\n",
    "                print((context,w,lp))\n",
    "            context = [w]\n",
    "        return result\n",
    "\n",
    "    def generateSentence(self,verbose=False,goryDetails=False):\n",
    "        context = [boundaryToken]\n",
    "        result = []\n",
    "        w = None\n",
    "        while not w == boundaryToken:\n",
    "            r = random.random() # returns a random float between 0 and 1\n",
    "            x = 0\n",
    "            c = self.probs[stringify_context(context)] # this will be a Counter\n",
    "            for k,v in list(c.items()):\n",
    "                x = x + v\n",
    "                if goryDetails:\n",
    "                    print((r,context,x,k,v))\n",
    "                if x > r: # choose this word\n",
    "                    w = k\n",
    "                    result.append(w)\n",
    "                    context = [w]\n",
    "                    break\n",
    "            if verbose:\n",
    "                print(w)\n",
    "        result.pop() # drop the boundary token\n",
    "        return result\n",
    "\n",
    "#ng=ngrams(3,train[3:4],boundaryToken=\"</s>\",verbose=False)\n",
    "#print ng\n",
    "print(train[4:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'That white'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4a6ae1de9dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNgramModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"That white rabbit\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoreSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#m.generateSentence(verbose=False, goryDetails=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#m = BigramModel(train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a1ae86849ab4>\u001b[0m in \u001b[0;36mscoreSentence\u001b[0;34m(self, sentence, addBeginToken, verbose)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a1ae86849ab4>\u001b[0m in \u001b[0;36mprob\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m\"\"\"takes a word string and a context which is a list of word strings, and returns the probability of the word\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscoreSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maddBeginToken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'That white'"
     ]
    }
   ],
   "source": [
    "m = NgramModel(train, n=3, verbose=False)\n",
    "test = \"That white rabbit\".split()\n",
    "m.scoreSentence(test, verbose=False)\n",
    "#m.generateSentence(verbose=False, goryDetails=False)\n",
    "#m = BigramModel(train)\n",
    "#test_sentence = ['That','white','rabbit']\n",
    "#m.scoreSentence(test_sentence,verbose=True)\n",
    "#m.generateSentence(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Alice ' s a vegetable . </s>\n"
     ]
    }
   ],
   "source": [
    "out = m.generateSentence(verbose=False, goryDetails=False)\n",
    "print(\" \".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        font-size: 110%;\n",
       "        margin-left:5% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 110%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "            font-size: 110%;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../css/notebook.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
