{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loglinear Models in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used to classify a name as male or female:\n",
      "{   'alwayson': True,\n",
      "    'count(a)': 1,\n",
      "    'count(b)': 0,\n",
      "    'count(c)': 0,\n",
      "    'count(d)': 0,\n",
      "    'count(e)': 0,\n",
      "    'count(f)': 0,\n",
      "    'count(g)': 0,\n",
      "    'count(h)': 0,\n",
      "    'count(i)': 0,\n",
      "    'count(j)': 0,\n",
      "    'count(k)': 0,\n",
      "    'count(l)': 0,\n",
      "    'count(m)': 0,\n",
      "    'count(n)': 1,\n",
      "    'count(o)': 2,\n",
      "    'count(p)': 1,\n",
      "    'count(q)': 0,\n",
      "    'count(r)': 0,\n",
      "    'count(s)': 0,\n",
      "    'count(t)': 0,\n",
      "    'count(u)': 0,\n",
      "    'count(v)': 0,\n",
      "    'count(w)': 0,\n",
      "    'count(x)': 0,\n",
      "    'count(y)': 0,\n",
      "    'count(z)': 0,\n",
      "    'endswith': 'p',\n",
      "    'has(a)': True,\n",
      "    'has(b)': False,\n",
      "    'has(c)': False,\n",
      "    'has(d)': False,\n",
      "    'has(e)': False,\n",
      "    'has(f)': False,\n",
      "    'has(g)': False,\n",
      "    'has(h)': False,\n",
      "    'has(i)': False,\n",
      "    'has(j)': False,\n",
      "    'has(k)': False,\n",
      "    'has(l)': False,\n",
      "    'has(m)': False,\n",
      "    'has(n)': True,\n",
      "    'has(o)': True,\n",
      "    'has(p)': True,\n",
      "    'has(q)': False,\n",
      "    'has(r)': False,\n",
      "    'has(s)': False,\n",
      "    'has(t)': False,\n",
      "    'has(u)': False,\n",
      "    'has(v)': False,\n",
      "    'has(w)': False,\n",
      "    'has(x)': False,\n",
      "    'has(y)': False,\n",
      "    'has(z)': False,\n",
      "    'startswith': 'a'}\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pprint\n",
    "from nltk.classify.maxent import MaxentClassifier\n",
    "from nltk.classify.util import names_demo, names_demo_features\n",
    "\n",
    "print(\"Features used to classify a name as male or female:\")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "test_features = names_demo_features(\"anoop\")\n",
    "pp.pprint(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loglinear classifier and run on some example input names:\n",
      "Training classifier...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.370\n",
      "             2          -0.61189        0.630\n",
      "             3          -0.59849        0.630\n",
      "             4          -0.58583        0.631\n",
      "         Final          -0.57390        0.637\n",
      "Testing classifier...\n",
      "Accuracy: 0.6340\n",
      "Avg. log likelihood: -0.8718\n",
      "\n",
      "Unseen Names      P(Male)  P(Female)\n",
      "----------------------------------------\n",
      "  Kelli            0.3185  *0.6815\n",
      "  Er              *0.4190   0.5810\n",
      "  Ally             0.3498  *0.6502\n",
      "  Stephan         *0.4124   0.5876\n",
      "  Chriss           0.3985  *0.6015\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loglinear classifier and run on some example input names:\")\n",
    "def mytrain(train_toks):\n",
    "    return MaxentClassifier.train(train_toks, max_iter=5)\n",
    "loglinear = names_demo(mytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NaiveBayes classifier and run on some example input names:\n",
      "Training classifier...\n",
      "Testing classifier...\n",
      "Accuracy: 0.7820\n",
      "Avg. log likelihood: -0.7476\n",
      "\n",
      "Unseen Names      P(Male)  P(Female)\n",
      "----------------------------------------\n",
      "  Kelli            0.0132  *0.9868\n",
      "  Er              *0.8826   0.1174\n",
      "  Ally             0.0903  *0.9097\n",
      "  Stephan         *0.8361   0.1639\n",
      "  Chriss           0.6864  *0.3136\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.naivebayes import NaiveBayesClassifier\n",
    "print(\"Train NaiveBayes classifier and run on some example input names:\")\n",
    "naivebayes = names_demo(NaiveBayesClassifier.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run trained classifier on input name: vivian\n",
      "P(male|vivian)=0.3195339612553724\n",
      "P(female|vivian)=0.6804660387446277\n",
      "  Feature                                           female    male\n",
      "  ----------------------------------------------------------------\n",
      "  count(v)==2 (1)                                    0.044\n",
      "  endswith=='n' (1)                                 -0.028\n",
      "  count(i)==2 (1)                                    0.020\n",
      "  has(i)==True (1)                                   0.016\n",
      "  has(a)==True (1)                                   0.016\n",
      "  startswith=='v' (1)                                0.013\n",
      "  has(n)==True (1)                                   0.012\n",
      "  count(o)==0 (1)                                    0.011\n",
      "  has(o)==False (1)                                  0.011\n",
      "  count(r)==0 (1)                                    0.010\n",
      "  has(r)==False (1)                                  0.010\n",
      "  count(a)==1 (1)                                    0.009\n",
      "  count(w)==0 (1)                                    0.008\n",
      "  has(w)==False (1)                                  0.008\n",
      "  count(u)==0 (1)                                    0.008\n",
      "  has(u)==False (1)                                  0.008\n",
      "  count(h)==0 (1)                                    0.008\n",
      "  has(h)==False (1)                                  0.008\n",
      "  has(v)==True (1)                                  -0.008\n",
      "  count(d)==0 (1)                                    0.008\n",
      "  has(d)==False (1)                                  0.008\n",
      "  count(n)==1 (1)                                    0.008\n",
      "  count(t)==0 (1)                                    0.007\n",
      "  has(t)==False (1)                                  0.007\n",
      "  count(m)==0 (1)                                    0.007\n",
      "  has(m)==False (1)                                  0.007\n",
      "  count(s)==0 (1)                                    0.007\n",
      "  has(s)==False (1)                                  0.007\n",
      "  count(f)==0 (1)                                    0.007\n",
      "  has(f)==False (1)                                  0.007\n",
      "  count(g)==0 (1)                                    0.007\n",
      "  has(g)==False (1)                                  0.007\n",
      "  count(p)==0 (1)                                    0.007\n",
      "  has(p)==False (1)                                  0.007\n",
      "  count(b)==0 (1)                                    0.007\n",
      "  has(b)==False (1)                                  0.007\n",
      "  count(z)==0 (1)                                    0.006\n",
      "  has(z)==False (1)                                  0.006\n",
      "  count(k)==0 (1)                                    0.006\n",
      "  has(k)==False (1)                                  0.006\n",
      "  count(x)==0 (1)                                    0.006\n",
      "  has(x)==False (1)                                  0.006\n",
      "  alwayson==True (1)                                 0.006\n",
      "  count(c)==0 (1)                                    0.006\n",
      "  has(c)==False (1)                                  0.006\n",
      "  count(q)==0 (1)                                    0.006\n",
      "  has(q)==False (1)                                  0.006\n",
      "  count(j)==0 (1)                                    0.005\n",
      "  has(j)==False (1)                                  0.005\n",
      "  count(y)==0 (1)                                    0.005\n",
      "  has(y)==False (1)                                  0.005\n",
      "  count(l)==0 (1)                                    0.001\n",
      "  has(l)==False (1)                                  0.001\n",
      "  count(e)==0 (1)                                   -0.001\n",
      "  has(e)==False (1)                                 -0.001\n",
      "  count(v)==2 (1)                                           -0.193\n",
      "  count(i)==2 (1)                                           -0.038\n",
      "  endswith=='n' (1)                                          0.032\n",
      "  has(i)==True (1)                                          -0.028\n",
      "  has(a)==True (1)                                          -0.027\n",
      "  startswith=='v' (1)                                       -0.022\n",
      "  has(n)==True (1)                                          -0.019\n",
      "  count(o)==0 (1)                                           -0.017\n",
      "  has(o)==False (1)                                         -0.017\n",
      "  count(r)==0 (1)                                           -0.016\n",
      "  has(r)==False (1)                                         -0.016\n",
      "  count(a)==1 (1)                                           -0.013\n",
      "  has(v)==True (1)                                           0.013\n",
      "  count(w)==0 (1)                                           -0.012\n",
      "  has(w)==False (1)                                         -0.012\n",
      "  count(u)==0 (1)                                           -0.012\n",
      "  has(u)==False (1)                                         -0.012\n",
      "  count(h)==0 (1)                                           -0.011\n",
      "  has(h)==False (1)                                         -0.011\n",
      "  count(d)==0 (1)                                           -0.011\n",
      "  has(d)==False (1)                                         -0.011\n",
      "  count(n)==1 (1)                                           -0.011\n",
      "  count(t)==0 (1)                                           -0.010\n",
      "  has(t)==False (1)                                         -0.010\n",
      "  count(m)==0 (1)                                           -0.010\n",
      "  has(m)==False (1)                                         -0.010\n",
      "  count(s)==0 (1)                                           -0.010\n",
      "  has(s)==False (1)                                         -0.010\n",
      "  count(f)==0 (1)                                           -0.009\n",
      "  has(f)==False (1)                                         -0.009\n",
      "  count(g)==0 (1)                                           -0.009\n",
      "  has(g)==False (1)                                         -0.009\n",
      "  count(p)==0 (1)                                           -0.009\n",
      "  has(p)==False (1)                                         -0.009\n",
      "  count(b)==0 (1)                                           -0.009\n",
      "  has(b)==False (1)                                         -0.009\n",
      "  count(z)==0 (1)                                           -0.008\n",
      "  has(z)==False (1)                                         -0.008\n",
      "  count(k)==0 (1)                                           -0.008\n",
      "  has(k)==False (1)                                         -0.008\n",
      "  count(x)==0 (1)                                           -0.008\n",
      "  has(x)==False (1)                                         -0.008\n",
      "  alwayson==True (1)                                        -0.007\n",
      "  count(c)==0 (1)                                           -0.007\n",
      "  has(c)==False (1)                                         -0.007\n",
      "  count(q)==0 (1)                                           -0.007\n",
      "  has(q)==False (1)                                         -0.007\n",
      "  count(j)==0 (1)                                           -0.007\n",
      "  has(j)==False (1)                                         -0.007\n",
      "  count(y)==0 (1)                                           -0.006\n",
      "  has(y)==False (1)                                         -0.006\n",
      "  count(e)==0 (1)                                            0.002\n",
      "  has(e)==False (1)                                          0.002\n",
      "  count(l)==0 (1)                                            0.001\n",
      "  has(l)==False (1)                                          0.001\n",
      "  -----------------------------------------------------------------\n",
      "  TOTAL:                                             0.392  -0.699\n",
      "  PROBS:                                             0.680   0.320\n"
     ]
    }
   ],
   "source": [
    "name='vivian'\n",
    "print(\"Run trained classifier on input name:\", name)\n",
    "test_features = names_demo_features(name)\n",
    "output = loglinear.prob_classify(test_features)\n",
    "print(\"P(male|{0})={1}\".format(name,output.prob('male')))\n",
    "print(\"P(female|{0})={1}\".format(name,output.prob('female')))\n",
    "loglinear.explain(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -0.317 endswith=='a' and label is 'male'\n",
      "  -0.208 endswith=='p' and label is 'female'\n",
      "  -0.202 endswith=='v' and label is 'female'\n",
      "  -0.193 count(v)==2 and label is 'male'\n",
      "  -0.164 endswith=='f' and label is 'female'\n",
      "  -0.152 endswith=='m' and label is 'female'\n",
      "  -0.146 endswith=='d' and label is 'female'\n",
      "  -0.122 endswith=='o' and label is 'female'\n",
      "  -0.118 count(a)==3 and label is 'male'\n",
      "  -0.110 endswith=='u' and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "loglinear.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loglinear Model for Prepositional Phrase Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 20801\n",
      "PPAttachment(sent='9688', verb='won', noun1='approval', prep='from', noun2='Board', attachment='V')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import ppattach\n",
    "print(\"Total:\",len(ppattach.attachments('training')))\n",
    "item = random.choice(ppattach.attachments('training'))\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Type              Feature Value                 \n",
      "-------------------------------------------------------\n",
      "prep                      from                          \n",
      "verb                      won                           \n",
      "noun1                     approval                      \n",
      "noun2                     Board                         \n",
      "prep+noun1                from::approval                \n",
      "prep+noun2                from::Board                   \n",
      "noun1+noun2               approval::Board               \n",
      "verb+noun1                won::approval                 \n",
      "verb+noun2                won::Board                    \n",
      "verb+prep                 won::from                     \n",
      "noun1+prep                approval::from                \n",
      "verb+noun1+noun2          won::approval::Board          \n",
      "verb+prep+noun2           won::from::Board              \n",
      "noun1+prep+noun2          approval::from::Board         \n",
      "verb+noun1+prep           won::approval::from           \n",
      "verb+noun1+prep+noun2     won::approval::from::Board    \n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import accuracy\n",
    "\n",
    "def j(*args):\n",
    "    return '::'.join(list(args))\n",
    "\n",
    "def print_feats(feats):\n",
    "    width1, width2 = 25,30\n",
    "    print(\"{:<{col1}} {:<{col2}}\".format('Feature Type','Feature Value',col1=width1,col2=width2))\n",
    "    print(width1*\"-\" + width2*\"-\")\n",
    "    for k, v in feats.items():\n",
    "        print(\"{:<{col1}} {:<{col2}}\".format(k,v,col1=width1,col2=width2))\n",
    "\n",
    "# verb='join', noun1='board', prep='as', noun2='director'\n",
    "def ppattach_feature(item):\n",
    "    return {\n",
    "        'prep': item.prep,\n",
    "        'verb': item.verb,\n",
    "        'noun1': item.noun1,\n",
    "        'noun2': item.noun2,\n",
    "        'prep+noun1': j(item.prep, item.noun1),\n",
    "        'prep+noun2': j(item.prep, item.noun2),\n",
    "        'noun1+noun2': j(item.noun1, item.noun2),\n",
    "        'verb+noun1': j(item.verb, item.noun1),\n",
    "        'verb+noun2': j(item.verb, item.noun2),\n",
    "        'verb+prep': j(item.verb, item.prep),\n",
    "        'noun1+prep': j(item.noun1, item.prep),\n",
    "        'prep+noun2': j(item.prep, item.noun2),\n",
    "        'verb+noun1+noun2': j(item.verb, item.noun1, item.noun2),\n",
    "        'verb+prep+noun2': j(item.verb, item.prep, item.noun2),\n",
    "        'noun1+prep+noun2': j(item.noun1, item.prep, item.noun2),\n",
    "        'verb+noun1+prep': j(item.verb, item.noun1, item.prep),\n",
    "        'verb+noun1+prep+noun2': j(item.verb, item.noun1, item.prep, item.noun2),\n",
    "        }\n",
    "\n",
    "print_feats(ppattach_feature(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train classifier ...\n",
      "  ==> Training (10 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.478\n",
      "             2          -0.29111        0.970\n",
      "             3          -0.20642        0.986\n",
      "             4          -0.16328        0.992\n",
      "             5          -0.13608        0.995\n",
      "             6          -0.11710        0.996\n",
      "             7          -0.10300        0.997\n",
      "             8          -0.09208        0.997\n",
      "             9          -0.08335        0.997\n",
      "         Final          -0.07621        0.997\n",
      "finished training classifier\n",
      "all:dev:0.842040\n",
      "all:test:0.840168\n"
     ]
    }
   ],
   "source": [
    "train_set = [ (ppattach_feature(item), item.attachment) for item in ppattach.attachments('training') ]\n",
    "dev_set = [ (ppattach_feature(item), item.attachment) for item in ppattach.attachments('devset') ]\n",
    "test_set = [ (ppattach_feature(item), item.attachment) for item in ppattach.attachments('test') ]\n",
    "print(\"starting to train classifier ...\")\n",
    "maxent_classifier = MaxentClassifier.train(train_set, algorithm='IIS', max_iter=10, count_cutoff=5)\n",
    "print(\"finished training classifier\")\n",
    "devacc = accuracy(maxent_classifier, dev_set)\n",
    "testacc = accuracy(maxent_classifier, test_set)\n",
    "print(\"all:dev:%lf\" % (devacc))\n",
    "print(\"all:test:%lf\" % (testacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train classifier ...\n",
      "finished training classifier\n",
      "all:dev:0.837584\n",
      "all:test:0.837908\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "print(\"starting to train classifier ...\")\n",
    "nb_classifier = NaiveBayesClassifier.train(train_set)\n",
    "print(\"finished training classifier\")\n",
    "devacc = accuracy(nb_classifier, dev_set)\n",
    "testacc = accuracy(nb_classifier, test_set)\n",
    "print(\"all:dev:%lf\" % (devacc))\n",
    "print(\"all:test:%lf\" % (testacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves\n",
    "\n",
    "Train on increasing size of training data and track accuracy on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.486\n",
      "             2          -0.28175        0.988\n",
      "             3          -0.20531        0.997\n",
      "             4          -0.16289        0.998\n",
      "         Final          -0.13537        0.999\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 2000 = 0.782867\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.493\n",
      "             2          -0.27395        0.982\n",
      "             3          -0.19784        0.995\n",
      "             4          -0.15679        0.998\n",
      "         Final          -0.13035        0.998\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 4000 = 0.796979\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.485\n",
      "             2          -0.27807        0.979\n",
      "             3          -0.19983        0.992\n",
      "             4          -0.15828        0.996\n",
      "         Final          -0.13166        0.998\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 6000 = 0.820748\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.28355        0.977\n",
      "             3          -0.20232        0.990\n",
      "             4          -0.16003        0.995\n",
      "         Final          -0.13310        0.997\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 8000 = 0.816291\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.511\n",
      "             2          -0.28472        0.974\n",
      "             3          -0.20248        0.989\n",
      "             4          -0.16015        0.994\n",
      "         Final          -0.13331        0.996\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 10000 = 0.815796\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.501\n",
      "             2          -0.28459        0.975\n",
      "             3          -0.20226        0.989\n",
      "             4          -0.15998        0.994\n",
      "         Final          -0.13321        0.996\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 12000 = 0.820995\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "             2          -0.28701        0.973\n",
      "             3          -0.20385        0.988\n",
      "             4          -0.16126        0.994\n",
      "         Final          -0.13431        0.996\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 14000 = 0.826195\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.489\n",
      "             2          -0.28842        0.972\n",
      "             3          -0.20462        0.988\n",
      "             4          -0.16182        0.993\n",
      "         Final          -0.13480        0.995\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 16000 = 0.835108\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.483\n",
      "             2          -0.29236        0.972\n",
      "             3          -0.20717        0.987\n",
      "             4          -0.16375        0.992\n",
      "         Final          -0.13638        0.995\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 18000 = 0.837336\n",
      "starting to train classifier ...\n",
      "  ==> Training (5 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.478\n",
      "             2          -0.29037        0.970\n",
      "             3          -0.20584        0.986\n",
      "             4          -0.16278        0.992\n",
      "         Final          -0.13563        0.995\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 20000 = 0.837088\n",
      "starting to train classifier ...\n",
      "  ==> Training (10 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.478\n",
      "             2          -0.29037        0.970\n",
      "             3          -0.20584        0.986\n",
      "             4          -0.16278        0.992\n",
      "             5          -0.13563        0.995\n",
      "             6          -0.11669        0.996\n",
      "             7          -0.10263        0.997\n",
      "             8          -0.09174        0.997\n",
      "             9          -0.08303        0.997\n",
      "         Final          -0.07590        0.997\n",
      "finished training classifier\n",
      "accuracy on dev set for training size 20800 = 0.838326\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNX9//HXB0SQr4AgCgiCVrRsVXBBFK0RUSj61aq1\nZRHXulSp+tMqLq1AtVWsfltbtVXqAiigVb8YN0TFoKUg+AVkF6sVWV1AFBAwJJ/fH+cmDCEhEzKT\nOzN5Px+PeXDXuZ+5JPnMOeeec8zdERERKU+duAMQEZHMpSQhIiIVUpIQEZEKKUmIiEiFlCRERKRC\nShIiIlKhtCcJM+trZkvMbKmZDS1nf2MzyzezuWY238wuKrO/jpnNNrP8dMcqIiI7SmuSMLM6wANA\nH6AzMMDMOpQ57Gpgobt3BU4G7jOzPRL2XwssSmecIiJSvnSXJLoDH7r7MncvBCYAZ5U5xoFG0XIj\nYK27bwMwszZAP+DvaY5TRETKke4k0RpYnrC+ItqW6AGgk5mtAt4nlBxK/BG4kZBIRESkhmVCw3Uf\nYI67HwB0Ax40s73N7HTgM3efC1j0EhGRGrRH5YdUy0qgbcJ6m2hboouBuwDc/SMz+w/QAegJnGlm\n/YC9gEZmNsbdLyh7ETNTSUNEpIrcvdIv3+kuScwC2ptZOzPbE+gPlH1KaRnQG8DMWgCHAR+7+63u\n3tbdvxedN6W8BFHC3fXazdewYcNijyHbX7qHun/Zdv+SldaShLsXmdkQYDIhIT3q7ovN7Iqw2x8B\n7gSeMLN50Wk3ufu6dMYlIiLJSXd1E+4+Cfh+mW0PJyyvJrRL7Oo9pgJT0xKgiIhUKBMariVmeXl5\ncYeQ9XQPq0f3r3rSef+sKnVTmcrMPBc+h4hIun31FTz7LFx+ueEZ0HAtIiIx27IFnnsOzjkHDjoI\nXnst+XNVkhARyUHFxTB1Kjz1FDz/PHTrBoMGwbnnQpMmYJZcSSLtDdciIlJz5s2DJ5+E8eNh333h\n/PPDtjZtdu/9lCRERKpowwZ45x2YMiW8FiyAevWgfn1o0CD8W3Z5V/uqu7xpU6hOevJJ+OabUGKY\nNAk6d67+Z1V1k4hIJTZvhunTtyeFefOge3fo1Su8unUL1TtbtsDWreGVuFx2vTrL5e2rUwfOOCOU\nGnr2DOuVSba6SUlCRKSMwkKYOXN7Upg1Cw4/fHtSOO442GuvuKOsHiUJEZEkFRXB3Lnbk8K0adC+\n/fakcOKJ0KhR5e+TTZQkREQq4A6LFm1PClOnQqtW25PCSSdBs2ZxR5leShIiIhF3+Oij7Unhrbdg\n7723J4W8vJAkahMlCRGp1Vas2J4UpkwJVUolSeHkk0OnstpMSUJEapXPP4eCgu1J4auvQgmhJDEc\ndhiYpi4rpSQhIrXCxIlw++3w6afwwx9uTwpduiT3KGhtpR7XIpLzXngBrrgiDD2Rlwd76C9ayumW\nikhWevVVuOwyePllOOaYuKPJXUoSIpJ13nwTLrgglCSUINJLNXYiklXefhv69w9jFR1/fNzR5D4l\nCRHJGtOnh6Gux48PjdSSfkoSIpIV3nsPzjoLRo+G3r3jjqb2UJIQkYz3/vtw+ukwahT06xd3NLWL\nkoSIZLSFC6FvX3jggVCSkJqlJCEiGWvpUjjtNPjDH+C88+KOpnZSkhCRjPTRR3DKKXDHHWEyHYmH\nkoSIZJxly0KCuPVWuOSSuKOp3ZQkRCSjrFwZEsR118EvfhF3NKIkISIZY82akCAuuywkCYmfkoSI\nZIQvvgj9HwYOhKFD445GSqQ9SZhZXzNbYmZLzWyn/3oza2xm+WY218zmm9lF0fb6Zvaumc2Jtg9L\nd6wiEo916+DUU+HMM+E3v4k7GkmU1vkkzKwOsBQ4BVgFzAL6u/uShGNuARq7+y1m1hz4AGjh7tvM\nrKG7f2tmdYFpwDXuPrOc62g+CZEs9fXXoQTxwx/CvfdqYqCakux8EukuSXQHPnT3Ze5eCEwAynaH\ncaBRtNwIWOvu2wDc/dtoe33CiLXKBCI5ZMMG+NGP4NhjlSAyVbqTRGtgecL6imhbogeATma2Cngf\nuLZkh5nVMbM5wBrgdXefleZ4RaSGfPstnHEGdO4Mf/6zEkSmyoSG6z7AHHc/AOgGPGhmewO4e7G7\ndwPaAMeaWacY4xSRFNmyJQyx0a4dPPywphnNZOmedGgl0DZhvU20LdHFwF0A7v6Rmf0H6AC8V3KA\nu39jZm8BfYFF5V1o+PDhpct5eXnk5eVVP3oRSbmtW8Nw3/vuC489pgRRUwoKCigoKKjyeeluuK5L\naIg+BVgNzAQGuPvihGMeBD539xFm1oKQHI4glHIK3f1rM9sLeA24291fKec6argWyQKFhWEMpjp1\n4OmnoV69uCOqvZJtuE5rScLdi8xsCDCZ8Ef/UXdfbGZXhN3+CHAn8ISZzYtOu8nd15nZD4DR0RNS\ndYCny0sQIpIdtm2DQYPCv88/rwSRLdJakqgpKkmIZLaiIrjoIvjsM8jPhwYN4o5IMqIkISJSXAxX\nXAErVsDLLytBZBslCRFJG3cYMgQWL4bXXoOGDeOOSKpKSUJE0sIdrr8+zE39+uuw995xRyS7Q0lC\nRFLOPcwFUVAAU6ZAkyZxRyS7S0lCRFJuxAh46SV46y1o2jTuaKQ6lCREJKXuuiv0gSgogObN445G\nqktJQkRS5o9/DL2op06FFi3ijkZSQUlCRFLiwQfDQH1Tp8IBB8QdjaSKkoSIVNvf/w4jR4YE0bZt\n5cdL9lCSEJHdVlwMDz0Ed98dGqkPPjjuiCTVlCREZLfMng1XXRXmgXjzTTj00LgjknTQIL0iUiXr\n1oXk0K9fGG5j2jT4/vfjjkrSRUlCRJJSXByeXOrUKZQeFi+Giy/WfBC5TtVNIlKp2bPh6qvD8iuv\nwJFHxhuP1Bx9BxCRCn31VRigr18/uOyyULWkBFG7KEmIyE6Ki+Hxx6Fjx7C8aBFccomqlmojVTeJ\nyA7mzAlVS8XFYf6Ho46KOyKJk74XiAiwvWqpb1+49FL417+UIERJQqTWKy6GJ54ITy0VFYWnli69\nVFVLEqi6SaQWmzs3VC0VFsKLL8LRR8cdkWQafVcQqYXWr4df/hL69IGLLoIZM5QgpHxKEiK1SHEx\njB4dnloqLAxPLV12maqWpGKqbhKpJd5/P1Qtbd0K+flwzDFxRyTZQN8fRHLc+vVwzTVw2mlwwQWh\nakkJQpKlJCGSo9xhzJhQtbR1a6hauvxyqFs37sgkm6i6SSQHvf9+6POwZQu88AJ07x53RJKtVJIQ\nySFffw3XXgunngqDB4eqJSUIqQ4lCZEc4A5jx4aqpc2bVbUkqaPqJpEsN29eeGpp82b43/+FY4+N\nOyLJJWkvSZhZXzNbYmZLzWxoOfsbm1m+mc01s/lmdlG0vY2ZTTGzhdH2a9Idq1Tdpk3w0UdxR1E7\nff01XHcd9O4NgwbBu+8qQUjqpTVJmFkd4AGgD9AZGGBmHcocdjWw0N27AicD95nZHsA24Hp37wwc\nB1xdzrkSs3vuCVNXnn8+fPhh3NHUDu7w5JOhamnTplC1dOWVqlqS9Eh3SaI78KG7L3P3QmACcFaZ\nYxxoFC03Ata6+zZ3X+PucwHcfSOwGGid5nilCkrqwd94Azp0gOOOCwPDffJJ3JHlrvnz4aST4I9/\nhOefh1GjoHnzuKOSXJbuJNEaWJ6wvoKd/9A/AHQys1XA+8C1Zd/EzA4CugLvpiVK2S3TpkGDBuGP\n1q9/HUoSBxwQhpe++mpYtSruCHPHN9/A9dfDKafAgAEwcyb06BF3VFIbZELDdR9gjrv3MrNDgNfN\n7PCo9ICZ7Q08C1xbsq08w4cPL13Oy8sjLy8vrUFLKEUMHgxmYb1pU7jjjtC79557oEsXuPhiGDoU\n9t8/3lizlTuMGwc33QQ/+hEsXAj77Rd3VJKNCgoKKCgoqPJ55u6pj6bkzc16AMPdvW+0fjPg7j4y\n4ZiXgLvcfVq0/iYw1N3fi9omXgJedff7d3EdT+fnkJ1t2QKtW4dZzNq2Lf+Y1avh978Pf+SuvBJu\nuAGaNavZOLPZggWhRLZhAzz4YKjOE0kVM8PdrbLj0l3dNAtob2btzGxPoD+QX+aYZUBvADNrARwG\nfBztewxYtKsEIfF4+WU44oiKEwRAq1bwl7+ERPLFF3DYYfDb34aqE6nYN9+EhNqrF/TvD7NmKUFI\nfNKaJNy9CBgCTAYWAhPcfbGZXWFml0eH3Qkcb2bzgNeBm9x9nZn1BAYBvcxsjpnNNrO+6YxXkldS\n1ZSMtm3hkUdC799//xvatw/VUZs2pTfGbFNStdSxYxiUb+FC+MUv9NSSxCut1U01RdVNNevLL+GQ\nQ2D5cmjcuOrnL1oEw4fDO+/AzTfDFVeEBvDabOHCULX09dfw0EMqOUj6ZUp1k+Sgp5+Gfv12L0FA\nmEv5mWfg1VdhyhQ49FB4+GH47rvUxpkNNmyAX/0KTj4ZzjsP3ntPCUIyi5KEVNnYsWFegurq2jWM\nUPrcc+GZ/w4dwqxp27ZV/70znTuMHx8+87p12xupVbUkmUbVTVIlS5fCD38IK1bAHil+gPrtt0N/\ni88/D9VRP/1pbk6ruXBhGMZ7/frw1NLxx8cdkdRGqm6StHjyydCZK9UJAkLymTo1PBH1xz+GksbE\nieFbdy7YsAFuvBHy8uDcc8NTS0oQkulUkpCkFReHBuvnnoMjj0zvtdzDY7a//jXUqxc66fXps73j\nXjZxD+04v/pVmOfh7ruhRYu4o5LaLtmShJKEJO2dd0KnuAULau6PdXFxaK+4/fbQEe/OO8M38Wyx\naFGoWlq3LlQt9ewZd0QigaqbJOVKGqxr8tt8nTrwk5+Ege2uvBJ+/vMwftH06TUXw+7YsCEMpXHS\nSXDOOeGpJSUIyUZKEpKULVtCNdOgQfFcv27dMBz54sUwcGDoiXz66TB7djzxVKSkaqlTp9AAv2BB\nKEmkow1HpCaoukmS8uyz8Ne/wptvxh1JsHUr/P3vYWyoww4L40g1aRJejRvverlx4/Q8arp4cUgI\nX34ZqpZOOCH11xBJFbVJSEqddRacfTZcdFHckezo229D4lq/PvRW/vrrMPZR2eXEbRs2wF57VS2p\nlLe/QYNQ9bZxY2hYf+wx+M1v4KqrVHKQzKckISnzxRdhvKUVK6BRo8qPz3Tu4Q97RUmksuWSf4uK\nQtLYti0k0ZEjoWXLuD+dSHKSTRL6viOVevppOOOM3EgQEL79N2pU/c/z3XchYWzbpuQguavShmsz\n+6WZNa2JYCQzVWXE19pkzz3D1KFKEJLLknm6qQUwy8yeMbO+ZtnYnUl21wcfwKefQu/ecUciInGo\nNEm4+6+BQ4FHgYuAD83s99FUo5Lj0jkMh4hkvqT6SUStwmui1zagKfCsmd2TxtgkZsXFqmoSqe0q\n/X5oZtcCFwBfAn8HbnT3QjOrA3wI3JTeECUu//xnaNzt2jXuSEQkLslUIjQDznH3ZYkb3b3YzM5I\nT1iSCUpKEWqFEqm9Ku0nYWY9gIXuviFabwx0dPd3ayC+pKifROpt2QIHHADz5kGbNnFHIyKplsoB\n/v4KbExY3xhtkxz24othOHAlCJHaLZkkscPXdHcvRp3wct6YMWqwFpHkksTHZnaNmdWLXtcCH6c7\nMInPF1+EuSPOOSfuSEQkbskkiSuB44GVwArgWODydAYl8ZowIbeG4RCR3acB/mQn3btvny5URHJT\nygb4M7MGwKVAZ6BByXZ3v6RaEUpGWrIEli8Ps7+JiCRT3TQWaAn0AaYCbYAN6QxK4jN2bJj5TcNw\niAgk109ijrt3M7N57n64mdUD3nH3HjUTYuVU3ZQaxcVw8MGQnw9HHBF3NCKSTqnsJ1EY/bvezLoA\nTYD9qxOcZKZ33gkzrilBiEiJZJLEI9F8Er8G8oFFwMhkLxANL77EzJaa2dBy9jc2s3wzm2tm883s\nooR9j5rZZ2Y2L9nrye7TYH4iUtYuq5uiQfx+4u7P7Nabh/OXAqcAq4BZQH93X5JwzC1AY3e/xcya\nAx8ALdx9m5mdQOjhPcbdD9/FdVTdVE2bN0Pr1jB/fvhXRHJbSqqbot7V1RnltTvwobsvc/dCYAJw\nVtnLACVP5DcC1rr7tuj6/wS+qsb1JUn5+XDUUUoQIrKjZKqb3jCzX5nZgWbWrOSV5Pu3BpYnrK+I\ntiV6AOhkZquA94Frk3xvSaGxY+GCC+KOQkQyTTIPOv4s+vfqhG0OfC9FMfQB5rh7r2i2u9fN7HB3\n31jZiYmGDx9eupyXl0deXl6Kwst9n38e5o6YMCHuSEQkXQoKCigoKKjyeWntcR0NMz7c3ftG6zcT\nJrobmXDMS8Bd7j4tWn8TGOru70Xr7YAX1SaRPn/+M8yaFUoTIlI7pLLHdbmVEO4+Jok4ZgHtoz/0\nq4H+wIAyxywDegPTzKwFcBg7DiBo0UvSZOxY+N3v4o5CRDJRMtVNxyQsNyA8qTQbqDRJuHuRmQ0B\nJhPaPx5198VmdkXY7Y8AdwJPJDzmepO7rwMws3FAHrCvmX0KDHP3x5P7aJKMxYth5UoNwyEi5aty\ndZOZ7QNMKKlCygSqbtp9t94KhYXwhz/EHYmI1KSUVTeVYxNw8G6cJxmmuBieeirMQiciUp5k2iRe\nJDzNBKHKqBOwW53rJLO8/Tbssw8cXuEjASJS2yVTkrg3YXkbsMzdV6QpHqlBGoZDRCqTzCiwBwOr\n3X1LtL4XYdiMT9IfXnLUJlF1334belcvXAgHHBB3NCJS01I5Cuw/gOKE9aJom2Sx/PwwA50ShIjs\nSjJJYg93/65kJVreM30hSU1QVZOIJCOZJPGFmZ1ZsmJmZwFfpi8kSbfPPoNp0+Dss+OOREQyXTIN\n11cCT5nZA9H6CkBDwWWxCRPgzDPhv/4r7khEJNMl3ZnOzPYGqOrAezVBDddVc9RRcPfdcOqpcUci\nInFJWcO1mf3ezPZx943uvtHMmprZnakJU2raokWwZg306hV3JCKSDZJpk/iRu68vWXH3r4B+6QtJ\n0mnsWBg0COrWjTsSEckGybRJ1DWz+u6+FUr7SdRPb1iSDiXDcLz8ctyRiEi2SCZJPAW8aWaPE4bs\nvggYnc6gJD2mToVmzeAHP4g7EhHJFpUmCXcfaWbvE+Z8cOA1oF26A5PUGzNGfSNEpGqSaZMA+IyQ\nIM4DegGL0xaRpMW338LEiTBwYNyRiEg2qbAkYWaHEWaRG0DoPPc04ZHZk2soNkmhF16AY4+FVq3i\njkREssmuqpuWAO8AZ7j7vwHM7P/VSFSSchqGQ0R2x66qm84hzEv9lpmNMrNT0FzTWWnNGpg+HX78\n47gjEZFsU2GScPeJ7t4f6AC8BVwH7G9mfzWz02oqQKm+8eM1DIeI7J4qzXFtZk0Jjdc/c/dT0hZV\nFWlYjl078sgwh/UpGfM/JiJxS3ZYjioliUylJFGxhQuhTx9Ytky9rEVku1ROOiRZTMNwiEh1qCSR\nw4qK4KCD4NVXoUuXuKMRkUyikoRQUADNmytBiMjuU5LIYWPHwgWaHkpEqkHVTTnq22+hdWtYvBha\ntow7GhHJNKpuquUmToQePZQgRKR6lCRylIbhEJFUSHuSMLO+ZrbEzJaa2dBy9jc2s3wzm2tm883s\nomTPlfKtXg0zZmgYDhGpvrQmCTOrAzwA9AE6AwPMrEOZw64GFrp7V+Bk4D4z2yPJc6Uc48eHBNGw\nYdyRiEi2S3dJojvwobsvc/dCYAJwVpljHGgULTcC1rr7tiTPlXKoqklEUiXdSaI1sDxhfUW0LdED\nQCczWwW8D1xbhXOljAUL4MsvIS8v7khEJBckM8d1uvUB5rh7LzM7BHjdzA6v6psMHz68dDkvL4+8\nWvpXsmQYjjp6JEFEEhQUFFBQUFDl89LaT8LMegDD3b1vtH4z4O4+MuGYl4C73H1atP4mMJSQwHZ5\nbsJ7qJ8EYRiOtm1h8mTo3DnuaEQkk2VKP4lZQHsza2dmewL9gfwyxywDegOYWQvgMODjJM+VBG+9\nFfpFKEGISKqktbrJ3YvMbAgwmZCQHnX3xWZ2RdjtjwB3Ak+Y2bzotJvcfR1AeeemM95spwZrEUk1\nDcuRIzZtgjZtYMkSaNEi7mhEJNNlSnWT1JCJE+G445QgRCS1lCRyxJgxqmoSkdRTdVMOWL0aOnWC\nlSvVy1pEkqPqplpk3Dg4+2wlCBFJPSWJHKCnmkQkXZQksty8ebBuHZx0UtyRiEguUpLIcg8/DOef\nr2E4RCQ9MmHsJtlNc+bAs8/CwoVxRyIiuUrfP7NUcTH84hfwu99B8+ZxRyMiuUpJIkuNGhWqmC65\nJO5IRCSXqZ9EFvr8c+jSBd54Aw6v8qDqIiLJ95NQkshCF14Yqpjuuy/uSEQkWyWbJNRwnWWmToUp\nU2DRorgjEZHaQG0SWeS770Jj9Z/+BI0aVX68iEh1KUlkkf/5HzjoIDjnnLgjEZHaQm0SWeKTT+Do\no2HmTPje9+KORkSynQb4yzHXXAPXXacEISI1Sw3XWeCFF2DpUvjHP+KORERqG1U3ZbhNm8JcEY8/\nDr16xR2NiOQK9ZPIEUOHwooV8NRTcUciIrlESSIHLFgAJ58M8+dDy5ZxRyMiuUQN11nOHa66CoYP\nV4IQkfgoSWSo0aNh82a48sq4IxGR2kzVTRlo7Vro3Bleein0jRARSTW1SWSxyy+HPfeEBx6IOxIR\nyVUa4C9LTZ8eShAawE9EMoHaJDLItm1hAL9774V99ok7GhERJYmM8pe/hHkiBgyIOxIRkSDtScLM\n+prZEjNbamZDy9n/KzObY2azzWy+mW0zs32ifddG2+ab2TXpjjVOK1aE+aoffBCs0lpCEZGakdaG\nazOrAywFTgFWAbOA/u6+pILjzwCuc/feZtYZGA8cA2wDXgWudPePyzkv6xuuzzsPOnSAO+6IOxIR\nqQ0ypTNdd+BDd1/m7oXABOCsXRw/gJAYADoC77r7VncvAt4GcnImhUmTYPZsuPXWuCMREdlRupNE\na2B5wvqKaNtOzGwvoC/wXLRpAXCimTU1s4ZAP+DANMYai82b4eqrw+Oue+0VdzQiIjvKpEdg/xv4\np7uvB3D3JWY2Engd2AjMAYpijC8t7roLunWDH/0o7khERHaW7iSxEmibsN4m2lae/myvagLA3R8H\nHgcws9+xY6lkB8OHDy9dzsvLIy8vb3firVFLl8JDD8HcuXFHIiK5rqCggIKCgiqfl+6G67rAB4SG\n69XATGCAuy8uc1wT4GOgjbtvTti+n7t/YWZtgUlAD3f/ppzrZF3DtTuceir06wfXXx93NCJS22RE\nj2t3LzKzIcBkQvvHo+6+2MyuCLv9kejQHwOvJSaIyHNm1gwoBK4qL0FkqwkT4IsvwrSkIiKZSmM3\nxeDrr6FjR3j2WTj++LijEZHaSAP8ZbBf/hK2bIFRo+KORERqq4yobpKd/d//wT/+AQsXxh2JiEjl\nNHZTDSoqCgP43XUX7Ltv3NGIiFROSaIGPfII1K8PF14YdyQiIslRm0QN+ewz+MEPYMoU6NIl7mgk\n1xx00EEsW7Ys7jAkA7Vr145PPvlkp+1quM4wgwdDq1Zwzz1xRyK5KPqFjzsMyUAV/Wyo4TqDvPUW\nvP22GqtFJPuoTSLNvvsOrroK7r8f9t477mhERKpGSSLN7r0X2reHs3Y1QLqISIZSm0Qa/ec/cMwx\n8N57cNBBcUcjuUxtElKR6rZJqCSRJu6hZ/UNNyhBiGSCfv36MXbs2LjDyDpKEmkycSJ8/HFIEiK1\n2cEHH8yUKVPiDoNXXnmFwYMHp+W9N2zYwHXXXUe7du1o3Lgxhx56KNdffz3r1q1Ly/VqkpJEGmzc\nCNdeG+aK2HPPuKMRyX1FRfHNR1ZYWEivXr1YvHgxkydP5ptvvmH69Ok0b96cmTNnVvn94vws5VGS\nSIMRIyAvL7xEpGIvvfQS3bp1o2nTppxwwgnMnz+/dN/IkSNp3749jRs3pkuXLkycOLF03+jRoznh\nhBO4/vrrad68OSNGjGD06NGceOKJ3HjjjTRr1oxDDjmESZMmlZ5z8skn89hjj5Wev6tjP/nkE046\n6SSaNGnCaaedxpAhQyoshYwePZoVK1YwceJEvv/97wPQvHlzbr31Vvr27QtAnTp1+Pjjj0vPufji\ni7n99tsBmDp1KgceeCD33HMPrVq14pJLLqFTp0688sorpccXFRWx//77MzeaoWzGjBn07NmTpk2b\n0q1bN6ZOnbp7/wFJUJJIsfnzYfTo8FSTiFRszpw5XHrppYwaNYp169ZxxRVXcOaZZ1JYWAhA+/bt\nmTZtGt988w3Dhg3j/PPP57PPPis9/91336V9+/Z8/vnn3HbbbaXbOnbsyNq1a7nxxhu59NJLK7z+\nzJkzKzx24MCB9OjRg7Vr1zJs2DDGjh2LWfltvG+++SZ9+/Zlr11MUl/RuSXWrFnD+vXr+fTTT3nk\nkUcYOHAg48aNK90/adIk9ttvP7p27crKlSs544wzuP322/nqq6+49957Offcc1m7du0ur7G7lCRS\nqLg4DOD329/C/vvHHY3IdmapeaXSqFGjuPLKKzn66KMxMwYPHkz9+vWZMWMGAOeeey4tWrQA4Lzz\nzuPQQw/dofqmdevWXHXVVdSpU4f69esDYXiSSy65BDPjwgsvZPXq1Xz++eflXr9du3blHrt8+XLe\ne+89RowYwR577EHPnj0588wzK/wca9eupVWrVrv8rJU9eVa3bl1GjBhBvXr1qF+/PgMGDCA/P58t\nW7YAMH78eAYMGADAU089xemnn06fPn0AOOWUUzj66KN3KHmkkpJECj3xBBQWwuWXxx2JyI7cU/NK\npWXLlnHffffRrFkzmjVrRtOmTVmxYgWrVq0CYMyYMaVVUU2bNmXhwoV8+eWXpecfeOCBO71ny5Yt\nS5dLvtlv3Lix3OtXdOyqVato1qwZDRo02OW1Suy7776sXr06mY9cof3224969eqVrh9yyCF06tSJ\nF198kc2bN5Ofn8+gQYOAcN+eeeaZHe7btGnTqh1DRTQsR4qsXQu33AKTJkEdpV6RSh144IHcdttt\n3HLLLTsvzp7wAAAKWklEQVTt+/TTT7n88st56623OO644wDo1q3bDt/IK6vC2V2tWrVi3bp1bNmy\npTRRLF++vMLr9e7dm9/85jds3ry5wiqnhg0b8u2335aur1mzZofEU9579+/fn3HjxlFUVETnzp05\n+OCDgXDfLrjgAh5++OHd/oxVoT9nKTJ0KPTvD926xR2JSOb57rvv2Lp1a+mrqKiIyy67jL/97W+l\nVUibNm3ilVdeYdOmTWzatIk6derQvHlziouLefzxx1mwYEGNxNq2bVuOPvpohg8fTmFhIdOnT+fF\nF1+s8PjBgwdz4IEHcu655/LBBx/g7qxdu5a77rqrtDG8a9eujBs3juLiYiZNmpRUQ3P//v2ZPHky\nf/3rXxk4cGDp9vPPP58XX3yRyZMnU1xczJYtW5g6dWppCSzVlCRSYNo0ePVVuOOOuCMRyUynn346\nDRs2ZK+99qJhw4aMGDGCo446ilGjRjFkyBCaNWvGYYcdxujRowHo2LEjN9xwAz169KBly5YsXLiQ\nE044ocrXTfyGXlnJI3H/U089xb/+9S+aN2/O7bffTv/+/UvbPcrac889eeONN+jQoQOnnnoqTZo0\nKW30PvbYYwG4//77yc/Pp2nTpowfP56zzz670thbtmzJcccdx4wZM/jZz35Wur1Nmza88MIL/P73\nv2e//fajXbt23HvvvRQXF1f6nrtDw3JUU2EhHHUU3HYbJPw/itQoDcuRXv3796djx44MGzYs7lCq\nTMNyxOzPf4aWLeGnP407EhFJlffee4+PP/4Yd2fSpEnk5+fz4x//OO6wYqGG62r66it48MHUPx4o\nIvFZs2YN55xzDuvWraNNmzb87W9/44gjjog7rFioukkkB6i6SSqi6iYREUkbJQkREamQkoSIiFRI\nDdciOaBdu3Zp64Es2a1du3bVOj/tDddm1hf4E6HU8qi7jyyz/1fAIMCBekBHoLm7rzez/wdcChQD\n84GL3f27cq6hhmsRkSrIiIZrM6sDPAD0AToDA8ysQ+Ix7n6vu3dz9yOBW4CCKEEcAPwSONLdDyeU\nevqnM97aqqCgIO4Qsp7uYfXo/lVPOu9futskugMfuvsydy8EJgBn7eL4AcD4hPW6wH+Z2R5AQyA9\ng5PUcvoFrT7dw+rR/auebE4SrYHlCesrom07MbO9gL7AcwDuvgq4D/gUWAmsd/c30hqtiIjsIJOe\nbvpv4J/uvh7AzPYhlDraAQcAe5vZwF2cLyIiKZbWhmsz6wEMd/e+0frNgJdtvI72PQ884+4TovWf\nAH3c/bJofTBwrLsPKedctVqLiFRRMg3X6X4EdhbQ3szaAasJDc8Dyh5kZk2AkwhPOZX4FOhhZg2A\nrcAp0fvtJJkPKiIiVZfWJOHuRWY2BJjM9kdgF5vZFWG3PxId+mPgNXffnHDuTDN7FpgDFEb/PoKI\niNSYnBjgT0RE0iOTGq6rzMz6mtkSM1tqZkPjjieTmNknZva+mc0xs5nRtqZmNtnMPjCz16JqvpLj\nbzGzD81ssZmdlrD9SDObF93jP8XxWWqKmT1qZp+Z2byEbSm7Z2a2p5lNiM6ZbmZta+7TpV8F92+Y\nma0ws9nRq2/CPt2/BGbWxsymmNlCM5tvZtdE2+P9GXT3rHwREty/CU8/1QPmAh3ijitTXsDHQNMy\n20YCN0XLQ4G7o+VOhOq8PYCDovtaUsp8FzgmWn6F8DBB7J8vTffsBKArMC8d9wz4BfBQtPwzYELc\nn7kG7t8w4Ppyju2o+7fTPWkJdI2W9wY+ADrE/TOYzSWJqnbUq22MnUuKZwGjo+XRhLYggDMJPyzb\n3P0T4EOgu5m1BBq5e8kDA2MSzsk57v5P4Ksym1N5zxLf61nCwxg5o4L7B+Fnsayz0P3bgbuvcfe5\n0fJGYDHQhph/BrM5SSTdUa+WcuB1M5tlZj+PtrVw988g/EAC+0fby97LldG21oT7WqI23uP9U3jP\nSs9x9yJgvZk1S1/oGWOImc01s78nVJXo/u2CmR1EKJXNILW/t1W+h9mcJGTXenoYD6sfcLWZnUhI\nHIn01ELVpfKe1YZHtx8CvufuXYE1hFEUUiUn75+Z7U34ln9tVKJI5+9tTs9MtxJIbHRpE20TwN1X\nR/9+AUwkVM99ZmYtAKIi6efR4SuBAxNOL7mXFW2vTVJ5z0r3mVldoLG7r0tf6PFz9y88qgAHRhF+\nDkH3r1zROHXPAmPd/YVoc6w/g9mcJEo76pnZnoSOevkxx5QRzKxh9G0EM/sv4DTCUOv5wEXRYRcC\nJT+E+UD/6MmHg4H2wMyoaPu1mXU3MwMuSDgnVxk7frtK5T3Lj94D4DxgSto+RXx2uH/RH7US5wAL\nomXdv/I9Bixy9/sTtsX7Mxh3i341nwboS3gC4EPg5rjjyZQXcDDhaa85hORwc7S9GfBGdM8mA/sk\nnHML4emIxcBpCduPit7jQ+D+uD9bmu/bOMJIw1sJPf4vBpqm6p4B9YFnou0zgIPi/sw1cP/GAPOi\nn8eJhPp13b/y719PoCjhd3d29DcuZb+3u3MP1ZlOREQqlM3VTSIikmZKEiIiUiElCRERqZCShIiI\nVEhJQkREKqQkISIiFVKSkJxmZs0sDJc+28xWR8NWl6wnNelWNAT2oZUcc5WZ7TTr4m7GfFYU41wz\nW2Bml6T6GiLJUj8JqTXM7HZgo7v/Tzn7zDPglyEaPeA/wJHu/pmZ1QPaufu/Yw5NaimVJKQ2SRwu\n4pBocpcnzWwB0NLMHjazmdGEL79OOPYdMzvczOqa2Vdmdlf0LX+amTWPjrkjYZKYd6Jj3o0mg+kR\nbW9oZs9GpYN/RCP0Hl4mxpJRUtcDuHthSYIouYaFyWlKSkNzzKzIzFqZ2f5m9lz0GWaYWXdEqklJ\nQmqz7wP3uXsXDwMiDnX37oQhmk8zsw7lnNMEeMvDqKYzgEsqenN3Pxa4iTDxDsAvgdXu3gW4I7pO\n2XO+IAy9sMzMnjKz/tH4O4nHrHD3bh5G+X0cGBfF/2dgZPQZfgY8mvytEClfUnWyIjnqI3efk7A+\nKKr/3wNoRZj5a0mZc75198nR8v8RZmMrz/MJx7SLlk8A7gZw93lmtrC8E939YjPrAvQmzETWC7i8\n7HFm9kPC4G09o029gcMSkkoTM6vv7lsriFGkUkoSUpttKlkws/bANcDR7r7BzMYCDco557uE5SIq\n/h3amsQxFY7l7+4LgAVmNh5YRJkkYWatgb8Bp5dJAsd4mExGJCVU3SS1WeIf6cbAN8BGM2sF9Eni\nnKqaRqgGwsx+QJjnecc3N2sUTRBVohuwrMwx9Qgjed7g7v9J2PUGoUqr5LgjqhGrCKAkIbVb6dNM\n7j6bMNzyYuAJ4J/lHUdys4JVdMxfgAOihvLfEEoIX5c5xoBbogbv2cCthCG3E51IaM/4XUIDdnNg\nCNDTzN6PrvFzRKpJj8CK1JBoJrA93H1rVL31GnCouxfHHJpIhdQmIVJz9gbeTOjEd7kShGQ6lSRE\nRKRCapMQEZEKKUmIiEiFlCRERKRCShIiIlIhJQkREamQkoSIiFTo/wOsdzZf/s28hAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104162490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk_size = 2000 \n",
    "x_axis = []\n",
    "y_axis = []\n",
    "\n",
    "def training_run(data, iters):\n",
    "    print \"starting to train classifier ...\"\n",
    "    #classifier = NaiveBayesClassifier.train(train_slice)\n",
    "    classifier = MaxentClassifier.train(train_slice, algorithm='IIS', max_iter=iters, count_cutoff=5)\n",
    "    print \"finished training classifier\"\n",
    "    acc = accuracy(classifier, dev_set)\n",
    "    print \"accuracy on dev set for training size %d = %f\" % (slice, acc)\n",
    "    return acc\n",
    "    \n",
    "for slice in range(len(train_set)):\n",
    "    if slice > 0 and slice % chunk_size == 0:\n",
    "        train_slice = train_set[:slice]\n",
    "        acc = training_run(train_slice,5)\n",
    "        x_axis.append(slice)\n",
    "        y_axis.append(acc)\n",
    "\n",
    "acc = training_run(train_set,10)\n",
    "x_axis.append(len(train_set))\n",
    "y_axis.append(acc)\n",
    "\n",
    "plt.xlim( (1,len(train_set)) )\n",
    "plt.plot(x_axis, y_axis, label='Learning Curve')\n",
    "\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train classifier ...\n",
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.478\n",
      "             2          -0.29111        0.970\n",
      "             3          -0.20642        0.986\n",
      "             4          -0.16328        0.992\n",
      "             5          -0.13608        0.995\n",
      "             6          -0.11710        0.996\n",
      "             7          -0.10300        0.997\n",
      "             8          -0.09208        0.997\n",
      "             9          -0.08335        0.997\n",
      "            10          -0.07621        0.997\n",
      "            11          -0.07024        0.997\n",
      "            12          -0.06519        0.997\n",
      "            13          -0.06085        0.997\n",
      "            14          -0.05708        0.997\n",
      "            15          -0.05378        0.997\n",
      "            16          -0.05086        0.997\n",
      "            17          -0.04827        0.997\n",
      "            18          -0.04594        0.997\n",
      "            19          -0.04384        0.997\n",
      "            20          -0.04194        0.997\n",
      "            21          -0.04021        0.997\n",
      "            22          -0.03863        0.997\n",
      "            23          -0.03718        0.997\n",
      "            24          -0.03584        0.997\n",
      "            25          -0.03461        0.997\n",
      "            26          -0.03346        0.997\n",
      "            27          -0.03240        0.997\n",
      "            28          -0.03141        0.997\n",
      "            29          -0.03048        0.997\n",
      "            30          -0.02962        0.997\n",
      "            31          -0.02880        0.997\n",
      "            32          -0.02804        0.997\n",
      "            33          -0.02732        0.997\n",
      "            34          -0.02664        0.997\n",
      "            35          -0.02600        0.997\n",
      "            36          -0.02539        0.997\n",
      "            37          -0.02482        0.997\n",
      "            38          -0.02427        0.997\n",
      "            39          -0.02375        0.997\n",
      "            40          -0.02326        0.997\n",
      "            41          -0.02279        0.997\n",
      "            42          -0.02234        0.997\n",
      "            43          -0.02191        0.997\n",
      "            44          -0.02150        0.997\n",
      "            45          -0.02110        0.997\n",
      "            46          -0.02073        0.997\n",
      "            47          -0.02037        0.997\n",
      "            48          -0.02002        0.997\n",
      "            49          -0.01969        0.997\n",
      "            50          -0.01937        0.997\n",
      "            51          -0.01906        0.997\n",
      "            52          -0.01877        0.997\n",
      "            53          -0.01848        0.997\n",
      "            54          -0.01821        0.997\n",
      "            55          -0.01794        0.997\n",
      "            56          -0.01769        0.997\n",
      "            57          -0.01744        0.997\n",
      "            58          -0.01720        0.997\n",
      "            59          -0.01697        0.997\n",
      "            60          -0.01675        0.997\n",
      "            61          -0.01653        0.997\n",
      "            62          -0.01632        0.997\n",
      "            63          -0.01612        0.997\n",
      "            64          -0.01593        0.997\n",
      "            65          -0.01574        0.997\n",
      "            66          -0.01555        0.997\n",
      "            67          -0.01537        0.997\n",
      "            68          -0.01520        0.997\n",
      "            69          -0.01503        0.997\n",
      "            70          -0.01486        0.997\n",
      "            71          -0.01470        0.997\n",
      "            72          -0.01455        0.997\n",
      "            73          -0.01439        0.997\n",
      "            74          -0.01425        0.997\n",
      "            75          -0.01410        0.997\n",
      "            76          -0.01396        0.997\n",
      "            77          -0.01383        0.997\n",
      "            78          -0.01369        0.997\n",
      "            79          -0.01356        0.997\n",
      "            80          -0.01344        0.997\n",
      "            81          -0.01331        0.997\n",
      "            82          -0.01319        0.997\n",
      "            83          -0.01308        0.997\n",
      "            84          -0.01296        0.997\n",
      "            85          -0.01285        0.997\n",
      "            86          -0.01274        0.997\n",
      "            87          -0.01263        0.997\n",
      "            88          -0.01253        0.997\n",
      "            89          -0.01242        0.997\n",
      "            90          -0.01232        0.997\n",
      "            91          -0.01223        0.997\n",
      "            92          -0.01213        0.997\n",
      "            93          -0.01204        0.997\n",
      "            94          -0.01194        0.997\n",
      "            95          -0.01185        0.997\n",
      "            96          -0.01177        0.997\n",
      "            97          -0.01168        0.997\n",
      "            98          -0.01160        0.997\n",
      "            99          -0.01151        0.997\n",
      "         Final          -0.01143        0.997\n",
      "finished training classifier\n",
      "all:dev:0.844021\n",
      "all:test:0.837585\n"
     ]
    }
   ],
   "source": [
    "print(\"starting to train classifier ...\")\n",
    "maxent_classifier = MaxentClassifier.train(train_set, algorithm='IIS', max_iter=100, count_cutoff=5)\n",
    "print(\"finished training classifier\")\n",
    "devacc = accuracy(maxent_classifier, dev_set)\n",
    "testacc = accuracy(maxent_classifier, test_set)\n",
    "print(\"all:dev:%lf\" % (devacc))\n",
    "print(\"all:test:%lf\" % (testacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        font-size: 110%;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 110%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "            font-size: 110%;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../css/notebook.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
